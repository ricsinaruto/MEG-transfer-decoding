import sys
import pytest
sys.path.append('..')


# Generated by CodiumAI
from transformers_quantized import TransformerQuantized
from args import Args
from torch.nn import Linear, Embedding, CrossEntropyLoss, MSELoss

from transformers import GPT2Config

"""
Code Analysis:
- The class 'TransformerQuantized' is a subclass of 'GPT2Model' and 'WavenetFullChannelMix' classes, which inherits their properties and methods.
- It is used for generating audio samples from a trained model.
- The 'build_model' method initializes the model's parameters and embeddings, including the quantization embedding, channel embedding, and positional embedding.
- The 'embedding_method' method adds up the embeddings for each input sample.
- The 'forward_head' method applies the linear output head to the model's output and reshapes it to the desired output shape.
- The 'forward' method applies the quantization embedding, channel embedding, and positional embedding to the input data, and then passes it through the GPT2 model. The output is then passed through the output head to get the final output.
- The 'get_cond' method retrieves the conditioning data for the model.
- The 'generate' method generates audio samples using the trained model and the given input data.
- The 'criterion' and 'mse_loss' fields define the loss functions used for training the model.
- The 'quant_levels', 'out_times', and 'save_preds' fields define the parameters for generating audio samples.
"""


@pytest.fixture
def args_test():
    args = Args()

    args.mu = 255
    args.sample_rate = 16000
    args.rf = 2000
    args.num_classes = 10

    n_embd = 12*8
    args.gpt2_config = GPT2Config(
        vocab_size=256,
        n_positions=256,
        n_embd=n_embd,
        n_layer=2,
        n_head=2,
        resid_pdrop=0.0,
        embd_pdrop=0.0,
        attn_pdrop=0.0,
        bos_token_id=255,
        eos_token_id=255,
        name_or_path=None,
        use_cache=False
    )

    args.class_emb = n_embd
    args.quant_emb = n_embd
    args.num_channels = 4
    args.channel_emb = n_embd

    return args


class TestTransformerQuantized:
    

    # Tests that the model's parameters and embeddings are initialized properly. tags: [happy path]
    def test_build_model(self, args_test):
        args = args_test
       
        model = TransformerQuantized(args)
        assert model.quant_levels == args.mu + 1
        assert model.out_times == args.sample_rate - args.rf
        assert model.save_preds == False
        assert isinstance(model.head, Linear)
        assert isinstance(model.cond_emb, Embedding)
        assert isinstance(model.quant_emb, Embedding)
        assert isinstance(model.ch_emb, Embedding)
        assert model.ch_ids.tolist() == [0, 1, 2, 3]

    # Tests that the model applies quantization embedding, channel embedding, and positional embedding to input data and generates the desired output shape. tags: [happy path]
    def test_forward(self):
        args = self.args
       
        model = TransformerQuantized(args)
        data = {'inputs': torch.randn(2, 4, 100)}
        output = model(data)
        assert output.shape == (2, 4, args.sample_rate - args.rf + 1, args.mu + 1)

    # Tests that the method generates audio samples using the trained model and the given input data. tags: [edge case]
    def test_generate(self):
        args = self.args
        
        model = TransformerQuantized(args)
        train_data = {'inputs': torch.randn(1, 4, 100)}
        output = model.generate(train_data)
        assert output.shape == (1, args.sample_rate)

    # Tests that the method retrieves the conditioning data for the model properly. tags: [happy path]
    def test_get_cond(self):
        args = self.args
        
        model = TransformerQuantized(args)
        data = {'inputs': torch.randn(2, 4, 100), 'condition': torch.tensor([[1], [2]])}
        cond = model.get_cond(data)
        assert cond.shape == (2 * args.num_channels, args.class_emb, 100)
        assert cond.sum() != 0

    # Tests that the method applies the linear output head to the model's output and reshapes it to the desired output shape. tags: [happy path]
    def test_forward_head(self):
        args = self.args
        model = TransformerQuantized(args)
        x = torch.randn(2 * args.num_channels, args.sample_rate - args.rf + 1, args.mu + 1)
        output = model.forward_head(x)
        assert output.shape == (2, args.num_channels, args.rf, args.mu + 1)

    # Tests that the loss functions used for training the model are defined properly. tags: [happy path]
    def test_loss_functions(self):
        args = self.args
        model = TransformerQuantized(args)
        criterion = model.criterion
        mse_loss = model.mse_loss
        assert isinstance(criterion, CrossEntropyLoss)
        assert isinstance(mse_loss, MSELoss)