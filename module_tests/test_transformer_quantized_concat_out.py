
"""
Code Analysis

Main functionalities:
The TransformerQuantizedConcatOut class is a subclass of the TransformerQuantized class and expands on it by concatenating the output across the channel dimension and applying a separate linear layer (head) to predict the output of each channel. This class is used for generating audio samples using a GPT-2 model with quantized outputs.

Methods:
- build_model(args): overrides the build_model method of the parent class to add a head parameter for each channel and a separate linear layer (head2) for predicting the output of each channel.
- forward_head(x): overrides the forward_head method of the parent class to reshape the output tensor, join the embedding and channel dimension, apply each channel's head, and return the output tensor.

Fields:
- head: a tensor of shape (num_channels, n_embd * num_channels, quant_emb) representing the head parameter for each channel.
- head2: a Linear layer for predicting the output of each channel.
"""
import os

os.environ["NVIDIA_VISIBLE_DEVICES"] = '1'
os.environ["CUDA_VISIBLE_DEVICES"] = '1'

# Generated by CodiumAI
import pytest
from transformers_quantized import TransformerQuantizedConcatOut
from args import Args
from torch.nn import Linear, Embedding, CrossEntropyLoss, MSELoss
from torch.nn.parameter import Parameter
import torch

from transformers import GPT2Config

@pytest.fixture
def args_test():
    args = Args()

    args.mu = 255
    args.sample_rate = 256
    args.rf = 128
    args.num_classes = 10

    n_embd = 12*8
    args.gpt2_config = GPT2Config(
        vocab_size=256,
        n_positions=256,
        n_embd=n_embd,
        n_layer=2,
        n_head=2,
        resid_pdrop=0.0,
        embd_pdrop=0.0,
        attn_pdrop=0.0,
        bos_token_id=255,
        eos_token_id=255,
        name_or_path=None,
        use_cache=False
    )

    args.class_emb = n_embd
    args.quant_emb = n_embd
    args.num_channels = 4
    args.channel_emb = n_embd

    args.cond_channels = args.class_emb + args.embedding_dim

    return args


class TestTransformerQuantizedConcatOut:

    # Tests that the class can be instantiated with valid arguments. tags: [happy path]
    def test_instantiation_valid_args(self, args_test):
        args = args_test
        model = TransformerQuantizedConcatOut(args).cuda()
        assert isinstance(model, TransformerQuantizedConcatOut)
        assert isinstance(model.head, Parameter)
        assert isinstance(model.head2, Linear)

    # Tests that the output of the forward_head method has the correct shape. tags: [general behavior]
    def test_output_shape(self, args_test):
        args = args_test
        model = TransformerQuantizedConcatOut(args).cuda()
        x = torch.randn(2 * args.num_channels, args.sample_rate, args.quant_emb).cuda()
        output = model.forward_head(x)
        assert output.shape == (2, args.num_channels, args.sample_rate - args.rf + 1, args.mu+1)
