{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "import struct\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from scipy.signal import stft, welch, butter, filtfilt\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from classifiers_linear import LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegTune(LogisticRegression):\n",
    "    def __init__(self,\n",
    "                 penalty='l1',\n",
    "                 *,\n",
    "                 dual=False,\n",
    "                 tol=0.0001,\n",
    "                 C=1.0,\n",
    "                 fit_intercept=True,\n",
    "                 intercept_scaling=1,\n",
    "                 class_weight=None,\n",
    "                 random_state=None,\n",
    "                 solver='liblinear',\n",
    "                 max_iter=100,\n",
    "                 multi_class='ovr',\n",
    "                 verbose=0,\n",
    "                 warm_start=False,\n",
    "                 n_jobs=None,\n",
    "                 l1_ratio=None,\n",
    "                 scaler=None,\n",
    "                 halfwin=7,\n",
    "                 overlap=2,\n",
    "                 num_channels=[0, 1, 2, 64, 65, 66]):\n",
    "        self.scaler = scaler\n",
    "        self.halfwin = halfwin\n",
    "        self.overlap = overlap\n",
    "        self.num_channels = num_channels\n",
    "        self.sr_data = 500\n",
    "        self.sample_rate = [0, 250]\n",
    "\n",
    "        super().__init__(penalty=penalty, C=C, solver=solver, multi_class=multi_class)\n",
    "\n",
    "    def fit_func(self, data, target):\n",
    "        super().fit(data, target)\n",
    "\n",
    "    def fit(self, data, target):\n",
    "        if self.scaler is None:\n",
    "            self.scaler_inst = FunctionTransformer(lambda x: x)\n",
    "        else:\n",
    "            self.scaler_inst = self.scaler()\n",
    "\n",
    "        num_chn = len(self.num_channels)\n",
    "\n",
    "        num_trials = data.shape[0]\n",
    "        data = data[:, ::int(1000 / self.sr_data), self.num_channels]\n",
    "        data = data[:, self.sample_rate[0]:self.sample_rate[1], :].reshape(-1, num_chn)\n",
    "\n",
    "        self.scaler_inst.fit(data)\n",
    "        \n",
    "        data = self.scaler_inst.transform(data)\n",
    "        data = data.reshape(num_trials, -1, num_chn)\n",
    "\n",
    "        args = Args()\n",
    "        args.sr_data = self.sr_data\n",
    "        args.halfwin = self.halfwin\n",
    "        args.overlap = self.overlap\n",
    "        data = wavelet_transform(data, args)\n",
    "        data = data.reshape(num_trials, -1)\n",
    "\n",
    "        # fit model\n",
    "        self.fit_func(data, target)\n",
    "\n",
    "    def predict_func(self, data):\n",
    "        return super().predict(data)\n",
    "\n",
    "    def predict(self, data):\n",
    "        num_chn = len(self.num_channels)\n",
    "\n",
    "        num_trials = data.shape[0]\n",
    "        data = data[:, ::int(1000 / self.sr_data), self.num_channels]\n",
    "        data = data[:, self.sample_rate[0]:self.sample_rate[1], :].reshape(-1, num_chn)\n",
    "\n",
    "        data = self.scaler_inst.transform(data)\n",
    "        data = data.reshape(num_trials, -1, num_chn)\n",
    "\n",
    "        args = Args()\n",
    "        args.sr_data = self.sr_data\n",
    "        args.halfwin = self.halfwin\n",
    "        args.overlap = self.overlap\n",
    "        data = wavelet_transform(data, args)\n",
    "        data = data.reshape(num_trials, -1)\n",
    "\n",
    "        # fit model\n",
    "        return self.predict_func(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LDATune(LinearDiscriminantAnalysis):\n",
    "    def __init__(self,\n",
    "                 solver='lsqr',\n",
    "                 shrinkage='auto',\n",
    "                 priors=None,\n",
    "                 n_components=None,\n",
    "                 store_covariance=False,\n",
    "                 tol=0.0001,\n",
    "                 covariance_estimator=None,\n",
    "                 pca_comps=0,\n",
    "                 scaler=None,\n",
    "                 halfwin=7,\n",
    "                 overlap=2,\n",
    "                 num_channels=[0, 1, 2, 64, 65, 66],\n",
    "                 wavelet=True):\n",
    "        self.scaler = scaler\n",
    "        self.halfwin = halfwin\n",
    "        self.overlap = overlap\n",
    "        self.num_channels = num_channels\n",
    "        self.pca_comps = pca_comps\n",
    "        self.sr_data = 500\n",
    "        self.sample_rate = [0, 250]\n",
    "        self.wavelet = wavelet\n",
    "\n",
    "        super().__init__(solver=solver, shrinkage=shrinkage)\n",
    "\n",
    "    def fit(self, data, target):\n",
    "        if self.scaler is None:\n",
    "            self.scaler_inst = FunctionTransformer(lambda x: x)\n",
    "        else:\n",
    "            self.scaler_inst = self.scaler()\n",
    "\n",
    "        num_chn = len(self.num_channels)\n",
    "\n",
    "        num_trials = data.shape[0]\n",
    "        data = data[:, ::int(1000 / self.sr_data), self.num_channels]\n",
    "        data = data[:, self.sample_rate[0]:self.sample_rate[1], :].reshape(-1, num_chn)\n",
    "\n",
    "        self.scaler_inst.fit(data)\n",
    "        \n",
    "        data = self.scaler_inst.transform(data)\n",
    "        data = data.reshape(num_trials, -1, num_chn)\n",
    "\n",
    "        args = Args()\n",
    "        args.sr_data = self.sr_data\n",
    "        args.halfwin = self.halfwin\n",
    "        args.overlap = self.overlap\n",
    "        if self.wavelet:\n",
    "            data = wavelet_transform(data, args)\n",
    "        data = data.reshape(num_trials, -1)\n",
    "\n",
    "        if self.pca_comps:\n",
    "            self.pca = PCA(n_components=self.pca_comps)\n",
    "            data = self.pca.fit_transform(data)\n",
    "\n",
    "        # fit model\n",
    "        super().fit(data, target)\n",
    "\n",
    "    def predict(self, data):\n",
    "        num_chn = len(self.num_channels)\n",
    "\n",
    "        num_trials = data.shape[0]\n",
    "        data = data[:, ::int(1000 / self.sr_data), self.num_channels]\n",
    "        data = data[:, self.sample_rate[0]:self.sample_rate[1], :].reshape(-1, num_chn)\n",
    "\n",
    "        data = self.scaler_inst.transform(data)\n",
    "        data = data.reshape(num_trials, -1, num_chn)\n",
    "\n",
    "        args = Args()\n",
    "        args.sr_data = self.sr_data\n",
    "        args.halfwin = self.halfwin\n",
    "        args.overlap = self.overlap\n",
    "        if self.wavelet:\n",
    "            data = wavelet_transform(data, args)\n",
    "        data = data.reshape(num_trials, -1)\n",
    "\n",
    "        if self.pca_comps:\n",
    "            data = self.pca.transform(data)\n",
    "\n",
    "        # fit model\n",
    "        return super().predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegL1(LDA):\n",
    "    '''\n",
    "    Logistic Regression model using the functionalities of the LDA class.\n",
    "    Uses L1 regularization.\n",
    "    '''\n",
    "    def __init__(self, args):\n",
    "        self.model = LogisticRegression(multi_class='ovr',\n",
    "                                        penalty='l1',\n",
    "                                        solver='liblinear',\n",
    "                                        C=args.C_reg)\n",
    "        self.fit_pca = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        n = 1  # can be used to do multiple runs, e.g. over subjects\n",
    "\n",
    "        self.model = LogisticRegL1\n",
    "        self.scaler = StandardScaler\n",
    "        self.C_reg = 1\n",
    "        self.sample_rate = [0, 250]\n",
    "        self.num_channels = [2, 64]  # 2, 64\n",
    "        self.sr_data = 500  # sampling rate used for downsampling\n",
    "        self.streaming_SR = 5\n",
    "        self.halfwin = 15  # 10\n",
    "        self.overlap = 2 # 2\n",
    "        self.result_dir = os.path.join(\n",
    "            '..',  # path(s) to save model and others\n",
    "            'results',\n",
    "            'stream2_jaw_6chan')\n",
    "\n",
    "        # experiment arguments\n",
    "        self.name = 'args.py'  # name of this file, don't change\n",
    "        self.fix_seed = False\n",
    "        self.common_dataset = False\n",
    "        self.load_dataset = True  # whether to load self.dataset\n",
    "        self.learning_rate = 0.0001  # learning rate for Adam\n",
    "        self.max_trials = 1  # ratio of training data (1=max)\n",
    "        self.val_max_trials = False\n",
    "        self.batch_size = 20  # batch size for training and validation data\n",
    "        self.epochs = 5000  # number of loops over training data\n",
    "        self.val_freq = 20  # how often to validate (in epochs)\n",
    "        self.print_freq = 5  # how often to print metrics (in epochs)\n",
    "        self.save_curves = True  # whether to save loss curves to file\n",
    "        self.load_model = False  # class of model to use\n",
    "        self.dataset = None  # dataset class for loading and handling data\n",
    "\n",
    "        # wavenet arguments\n",
    "        self.activation = None  # activation function for models\n",
    "        self.subjects = 1  # number of subjects used for training\n",
    "        self.embedding_dim = 0  # subject embedding size\n",
    "        self.p_drop = 0.6  # dropout probability\n",
    "        self.ch_mult = 2  # channel multiplier for hidden channels in wavenet\n",
    "        self.kernel_size = 2  # convolutional kernel size\n",
    "        self.timesteps = 1  # how many timesteps in the future to forecast\n",
    "        self.rf = 256  # receptive field of wavenet\n",
    "        rf = 128\n",
    "        ks = self.kernel_size\n",
    "        nl = int(np.log(rf) / np.log(ks))\n",
    "        dilations = [ks**i for i in range(nl)]\n",
    "        self.dilations = dilations + dilations   # dilation: 2^num_layers\n",
    "        #self.dilations = [1] + [2] + [4] * 7  # costum dilations\n",
    "\n",
    "        # classifier arguments\n",
    "        self.wavenet_class = None  # class of wavenet model\n",
    "        self.load_conv = 'y'  # where to load neural nerwork weights from\n",
    "        self.pred = False  # whether to use wavenet in prediction mode\n",
    "        self.init_model = True  # whether to reinitialize classifier\n",
    "        self.reg_semb = True  # whether to regularize subject embedding\n",
    "        self.fixed_wavenet = False  # whether to fix weights of wavenet\n",
    "        self.alpha_norm = 0.0  # regularization multiplier on weights\n",
    "        self.num_classes = 118  # number of classes for classification\n",
    "        self.units = [2200, 2000]  # hidden layer sizes of fully-connected block\n",
    "        self.dim_red = 80  # number of pca components for channel reduction\n",
    "        self.stft_freq = 0  # STFT frequency index for LDA_wavelet_freq model\n",
    "        self.decode_peak = 0.1\n",
    "        self.trial_average = False\n",
    "\n",
    "        # quantized wavenet arguments\n",
    "        self.mu = 255\n",
    "        self.residual_channels = 1024\n",
    "        self.dilation_channels = 1024\n",
    "        self.skip_channels = 1024\n",
    "        self.class_emb = 10\n",
    "        self.channel_emb = 30\n",
    "        self.cond_channels = self.class_emb + self.channel_emb\n",
    "        self.head_channels = int(self.skip_channels/2)\n",
    "        self.conv_bias = False\n",
    "\n",
    "        # dataset arguments\n",
    "        data_path = os.path.join('/', 'gpfs2', 'well', 'woolrich', 'projects',\n",
    "                                 'cichy118_cont', 'preproc_data_onepass', 'epoched')\n",
    "        self.data_path = [os.path.join(data_path, f'subj{i}') for i in range(n)]  # path(s) to data directory\n",
    "        self.numpy = True  # whether data is saved in numpy format\n",
    "        self.crop = 1  # cropping ratio for trials\n",
    "        self.shuffle = True\n",
    "        self.whiten = False  # pca components used in whitening\n",
    "        self.group_whiten = False  # whether to perform whitening at the GL\n",
    "        self.split = np.array([0, 0.2])  # validation split (start, end)\n",
    "        self.original_sr = 1000\n",
    "        self.save_data = True  # whether to save the created data\n",
    "        self.save_whiten = False\n",
    "        self.subjects_data = False  # list of subject inds to use in group data\n",
    "        self.num_clip = 25\n",
    "        self.dump_data = [os.path.join(data_path, f'subj{i}', 'train_data_trialnorm', 'c') for i in range(n)]  # path(s) for dumping data\n",
    "        self.load_data = self.dump_data  # path(s) for loading data files\n",
    "\n",
    "        # analysis arguments\n",
    "        self.kernelPFI = False\n",
    "        self.closest_chs = 'notebooks/closest1'  # channel neighbourhood size for spatial PFI\n",
    "        self.PFI_inverse = False  # invert which channels/timesteps to shuffle\n",
    "        self.pfich_timesteps = [[0, 50]]  # time window for spatiotemporal PFI\n",
    "        self.PFI_perms = 10  # number of PFI permutations\n",
    "        self.halfwin_uneven = False  # whether to use even or uneven window\n",
    "        self.generate_noise = 1  # noise used for wavenet generation\n",
    "        self.generate_length = self.sr_data * 1000  # generated timeseries len\n",
    "        self.generate_mode = 'IIR'  # IIR or FIR mode for wavenet generation\n",
    "        self.generate_input = 'gaussian_noise'  # input type for generation\n",
    "        self.individual = True  # whether to analyse individual kernels\n",
    "        self.anal_lr = 0.001  # learning rate for input backpropagation\n",
    "        self.anal_epochs = 200  # number of epochs for input backpropagation\n",
    "        self.norm_coeff = 0.0001  # L2 of input for input backpropagation\n",
    "        self.kernel_limit = 300  # max number of kernels to analyse\n",
    "\n",
    "        # simulation arguments\n",
    "        self.nonlinear_prenoise = True\n",
    "        self.nonlinear_data = True\n",
    "        self.seconds = 3000\n",
    "        self.events = 8\n",
    "        self.sim_num_channels = 1\n",
    "        self.sim_ar_order = 2\n",
    "        self.gamma_shape = 14\n",
    "        self.gamma_scale = 14\n",
    "        self.noise_std = 2.5\n",
    "        self.lambda_exp = 0.005\n",
    "        self.ar_shrink = 1.0\n",
    "        self.freqs = []\n",
    "        self.ar_noise_std = np.random.rand(self.events) / 5 + 0.8\n",
    "        self.max_len = 1000\n",
    "\n",
    "        # AR model arguments\n",
    "        self.order = 64\n",
    "        self.uni = False\n",
    "        self.save_AR = False\n",
    "        self.do_anal = False\n",
    "        self.AR_load_path = os.path.join(\n",
    "            'results',\n",
    "            'mrc',\n",
    "            '60subjects_notch_sensors_multiAR64')\n",
    "\n",
    "        # unused\n",
    "        self.num_plot = 1\n",
    "        self.plot_ch = 1\n",
    "        self.linear = False\n",
    "        self.num_samples_CPC = 20\n",
    "        self.dropout2d_bad = False\n",
    "        self.k_CPC = 1\n",
    "        self.groups = 1\n",
    "        self.conv1x1_groups = 1\n",
    "        self.pos_enc_type = 'cat'\n",
    "        self.pos_enc_d = 128\n",
    "        self.l1_loss = False\n",
    "        self.norm_alpha = self.alpha_norm\n",
    "        self.num_components = 0\n",
    "        self.resample = 7\n",
    "        self.save_norm = True\n",
    "        self.norm_path = os.path.join(data_path, 'norm_coeff')\n",
    "        self.pca_path = os.path.join(data_path, 'pca128_model')\n",
    "        self.load_pca = False\n",
    "        self.compare_model = False\n",
    "        self.channel_idx = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def control_code(code):\n",
    "    code_dict = {'CTRL_FromServer': 1, 'CTRL_FromClient': 2}\n",
    "    return code_dict.get(code, -1)\n",
    "\n",
    "def data_type(code):\n",
    "    data_dict = {'Data_Info': 1, 'Data_Eeg': 2, 'Data_Events': 3, 'Data_Impedance': 4}\n",
    "    return data_dict.get(code, -1)\n",
    "\n",
    "def request_type(code):\n",
    "    request_dict = {'RequestVersion': 1,\n",
    "                    'RequestChannelInfo': 3,\n",
    "                    'RequestBasicInfoAcq': 6,\n",
    "                    'RequestStreamingStart': 8,\n",
    "                    'RequestStreamingStop': 9}\n",
    "    return request_dict.get(code, -1)\n",
    "\n",
    "def init_header(chanID, code, request, samples, size_body, sizeUn):\n",
    "    # convert each character in chanID to uint8\n",
    "    c_chID = struct.pack('4B', *map(ord, chanID))\n",
    "    w_Code = struct.pack('>H', code)\n",
    "    w_Request = struct.pack('>H', request)\n",
    "    un_Sample = struct.pack('>I', samples)\n",
    "    un_Size = struct.pack('>I', size_body)\n",
    "    un_SizeUn = struct.pack('>I', sizeUn)\n",
    "\n",
    "    return c_chID + w_Code + w_Request + un_Sample + un_Size + un_SizeUn\n",
    "\n",
    "def block_type(code):\n",
    "    block_dict = {'DataTypeFloat32bit': 1,\n",
    "                  'DataTypeFloat32bitZIP': 2,\n",
    "                  'DataTypeEventList': 3}\n",
    "    return block_dict.get(code, -1)\n",
    "\n",
    "def info_type(code):\n",
    "    info_dict = {'InfoType_Version': 1,\n",
    "                 'InfoType_BasicInfo': 2,\n",
    "                 'InfoType_ChannelInfo': 4,\n",
    "                 'InfoType_StatusAmp': 7,\n",
    "                 'InfoType_Time': 9}\n",
    "    return info_dict.get(code, -1)\n",
    "\n",
    "def request_packet(con, packet_size):\n",
    "    count = 0\n",
    "    timeout = 20\n",
    "\n",
    "    while True:\n",
    "        data = con.recv(packet_size, 0)\n",
    "        if data or count == timeout:\n",
    "            break\n",
    "\n",
    "        count += 1\n",
    "        time.sleep(0.2)\n",
    "\n",
    "    return data\n",
    "\n",
    "def client_process_request(con, header, code, request, init):\n",
    "    header_size = len(header)\n",
    "\n",
    "    # send header if streaming start\n",
    "    if not init:\n",
    "        con.send(header)\n",
    "    \n",
    "    # get response header\n",
    "    data = request_packet(con, 20)\n",
    "    \n",
    "    temp_packet_size = 0\n",
    "    count = 0\n",
    "    timeout = 10\n",
    "    synch_packets = 5\n",
    "    data_out = bytearray()\n",
    "    message = {'code': None, 'request': None, 'start_sample': None, 'packet_size': None}\n",
    "    \n",
    "    message['code'] = struct.unpack('>H', data[4:6])[0]\n",
    "    message['request'] = struct.unpack('>H', data[6:8])[0]\n",
    "    message['start_sample'] = struct.unpack('>I', data[8:12])[0]\n",
    "    message['packet_size'] = struct.unpack('>I', data[12:16])[0]\n",
    "    \n",
    "    if message['code'] in code and message['request'] in request:\n",
    "        while temp_packet_size < message['packet_size'] and count < timeout:\n",
    "            data = request_packet(con, message['packet_size'])\n",
    "            temp_packet_size += len(data)\n",
    "            data_out += data\n",
    "            count += 1\n",
    "    else:\n",
    "        while count < synch_packets:\n",
    "            request_packet(con, message['packet_size'])\n",
    "            count += 1\n",
    "    \n",
    "    return data_out, message\n",
    "\n",
    "def client_get_basic_info(con):\n",
    "    basic_info = {}\n",
    "    max_chans = 300\n",
    "    header = init_header(\"CTRL\",\n",
    "                         control_code(\"CTRL_FromClient\"),\n",
    "                         request_type(\"RequestBasicInfoAcq\"),\n",
    "                         0, 0, 0)\n",
    "\n",
    "    basic_info_raw, message = client_process_request(con,\n",
    "                                                     header,\n",
    "                                                     [data_type(\"Data_Info\")],\n",
    "                                                     [info_type(\"InfoType_BasicInfo\")],\n",
    "                                                     0)\n",
    "\n",
    "    size = struct.unpack('<I', basic_info_raw[0:4])[0]\n",
    "    eeg_chan = struct.unpack('<I', basic_info_raw[4:8])[0]\n",
    "    sample_rate = struct.unpack('<I', basic_info_raw[8:12])[0]\n",
    "    data_size = struct.unpack('<I', basic_info_raw[12:16])[0]\n",
    "    allow_client_to_control_amp = struct.unpack('<I', basic_info_raw[16:20])[0]\n",
    "    allow_client_to_control_rec = struct.unpack('<I', basic_info_raw[20:24])[0]\n",
    "    \n",
    "    basic_info = {\n",
    "        'size': size,\n",
    "        'eeg_chan': eeg_chan,\n",
    "        'sample_rate': sample_rate,\n",
    "        'data_size': data_size,\n",
    "        'allow_client_to_control_amp': allow_client_to_control_amp,\n",
    "        'allow_client_to_control_rec': allow_client_to_control_rec\n",
    "    }\n",
    "\n",
    "    return basic_info\n",
    "\n",
    "def request_data_packet(con, basic_info, init=0):\n",
    "    segments = []\n",
    "    offset_event_type = 0\n",
    "    offset_event_latency = offset_event_type + 4\n",
    "    offset_event_start = offset_event_latency + 4\n",
    "    offset_event_end = offset_event_start + 4\n",
    "    offset_event_annotation = offset_event_end + 4\n",
    "\n",
    "    # raw length\n",
    "    event_struct_length = (offset_event_annotation + 520)//8*8\n",
    "\n",
    "    # Protocol variable definitions\n",
    "    data_types   = [data_type('Data_Eeg'), data_type('Data_Events'), data_type('Data_Impedance')]\n",
    "        \n",
    "    block_types  = [block_type('DataTypeFloat32bit'), block_type('DataTypeEventList')]\n",
    "\n",
    "    header = init_header('CTRL',\n",
    "                         control_code('CTRL_FromClient'),\n",
    "                         request_type('RequestStreamingStart'),\n",
    "                         0,0,0)\n",
    "\n",
    "    # get data\n",
    "    data, message = client_process_request(con, header, data_types, block_types, init=init)\n",
    "\n",
    "    # if data packet\n",
    "    if message['code'] == 2: \n",
    "        #receivedSamples = len(data) / (basic_info['data_size'] * basic_info['eeg_chan']) \n",
    "        #print(f\"Received {len(data) / 1000} kBytes, EEG, {receivedSamples} samples, Start sample = {message['startSample']}\")\n",
    "        return data, message\n",
    "\n",
    "    # if event packet\n",
    "    elif message['code'] == 3: \n",
    "        if message['packet_size'] % event_struct_length == 0:\n",
    "            num_events = message['packet_size'] // event_struct_length\n",
    "\n",
    "            if num_events > 0:\n",
    "                event_type = struct.unpack(\n",
    "                    '<I', data[offset_event_type:offset_event_latency])[0]\n",
    "                event_latency = struct.unpack(\n",
    "                    '<I', data[offset_event_latency:offset_event_start])[0]\n",
    "                event_annotation = struct.unpack(\n",
    "                    '<H', data[offset_event_annotation:offset_event_annotation+2])[0]\n",
    "                #print(f\"Event type {eventType}, Latency: {eventLatency}, Annotation: {chr(eventAnnotation)}\")\n",
    "\n",
    "                return {'event_type': event_type,\n",
    "                        'event_latency': event_latency,\n",
    "                        'event_annotation': chr(event_annotation)}, None\n",
    "        else:\n",
    "            print(\"ClientRequestDataPacket failed: unmatching event structure size\")\n",
    "\n",
    "    return data, message\n",
    "\n",
    "def stop_stream(con):\n",
    "    header = init_header('CTRL',\n",
    "                         control_code('CTRL_FromClient'),\n",
    "                         request_type('RequestStreamingStop'),\n",
    "                         0,0,0)\n",
    "    con.send(header)\n",
    "\n",
    "# decode data to numpy\n",
    "def decode_data(data, num_samples, basic_info):\n",
    "    dtype = np.float32 if basic_info['data_size'] == 4 else np.int16\n",
    "    return np.frombuffer(data, dtype=dtype).reshape(num_samples, basic_info[\"eeg_chan\"])\n",
    "\n",
    "# notch filter function\n",
    "def notch_filter(data, fs, f):\n",
    "    # creater butter filter\n",
    "    b, a = butter(5, [f - 1.5, f + 1.5], btype='bandstop', fs=fs, output='ba')\n",
    "    return filtfilt(b, a, data)\n",
    "\n",
    "def get_initial_data(sock, basic_info, SR):\n",
    "    data, _ = request_data_packet(sock, basic_info)\n",
    "    num_samples = len(data) // (basic_info[\"data_size\"] * basic_info[\"eeg_chan\"])\n",
    "\n",
    "    segments = []\n",
    "    events = []\n",
    "    train_data = []\n",
    "    train_target = []\n",
    "    start_sample = 0\n",
    "    last_sample_time = 0\n",
    "    sample_count = SR + 1\n",
    "\n",
    "    while True:\n",
    "        # start streaming\n",
    "        data, message = request_data_packet(sock, basic_info, 1)\n",
    "\n",
    "        # check if data is dict (event packet)\n",
    "        if isinstance(data, dict):\n",
    "            sample_count = 0\n",
    "            last_event = data['event_type']\n",
    "            last_latency = data['event_latency'] - start_sample\n",
    "            events.append(np.array([last_event, last_latency]))\n",
    "\n",
    "            # if we are at the end of experiment exit loop\n",
    "            if last_event == 7:\n",
    "                break\n",
    "        else:\n",
    "            # set start sample index\n",
    "            if not segments:\n",
    "                start_sample = message['start_sample']\n",
    "                last_sample_time = start_sample - num_samples\n",
    "            \n",
    "            if last_sample_time + num_samples != message['start_sample']:\n",
    "                print('Wrong sample time')\n",
    "            last_sample_time = message['start_sample']\n",
    "\n",
    "            # shape: samples x channels\n",
    "            packet = decode_data(data, num_samples, basic_info)\n",
    "            segments.append(packet)\n",
    "            sample_count += 1\n",
    "\n",
    "        # if we have enough samples to make a trial\n",
    "        if sample_count == SR:\n",
    "            # concatenate last 1 second of samples\n",
    "            trial = np.concatenate(segments[-SR-1:], axis=0)\n",
    "\n",
    "            # calculate latency of last event compared to trial start\n",
    "            latency = int(last_latency - (len(segments) - SR - 1) * 1000 / SR)\n",
    "            train_data.append(trial[latency:latency+1000, :])\n",
    "            train_target.append(last_event - 2)\n",
    "\n",
    "            print(f\"Trial {len(train_data)}: {last_event} at {last_latency} ms\")\n",
    "\n",
    "    stop_stream(sock)\n",
    "\n",
    "    return np.array(segments), np.array(events), np.array(train_data), np.array(train_target)\n",
    "\n",
    "def save_data(args, segments, events, train_data, train_target):\n",
    "    if not os.path.exists(args.result_dir):\n",
    "        os.makedirs(args.result_dir)\n",
    "\n",
    "    np.save(os.path.join(args.result_dir, 'events.npy'), events)\n",
    "    np.save(os.path.join(args.result_dir, 'segments.npy'), segments)\n",
    "    np.save(os.path.join(args.result_dir, 'train_data.npy'), train_data)\n",
    "    np.save(os.path.join(args.result_dir, 'train_target.npy'), train_target)\n",
    "\n",
    "def resegment_data(data, events):\n",
    "    train_data = []\n",
    "    train_target = []\n",
    "\n",
    "    for e in events[:-1]:\n",
    "        event = e[0]\n",
    "        latency = e[1]\n",
    "\n",
    "        # get trial data\n",
    "        trial = data[:, latency:latency+1000]\n",
    "\n",
    "        # append to train data\n",
    "        train_data.append(trial)\n",
    "        train_target.append(event - 2)\n",
    "\n",
    "    train_data = np.array(train_data).transpose(0, 2, 1)\n",
    "    return train_data, np.array(train_target)\n",
    "\n",
    "\n",
    "def wavelet_transform(data, args):\n",
    "    # trials, channels, samples\n",
    "    data = data.transpose(0, 2, 1)\n",
    "\n",
    "    f, t, data = stft(data,\n",
    "                      fs=args.sr_data,\n",
    "                      window='hamming',\n",
    "                      nperseg=args.halfwin*2,\n",
    "                      noverlap=args.overlap,\n",
    "                      boundary=None)\n",
    "\n",
    "    # concatenate wavelet coefficients\n",
    "    data = np.concatenate((data.real, data.imag), axis=2)\n",
    "\n",
    "    return data\n",
    "\n",
    "def train_and_predict(args, data, target=None, lda=None, scaler=None, wavelet=False):\n",
    "    init = False\n",
    "    if lda is None:\n",
    "        lda = args.model(args)\n",
    "\n",
    "        if args.scaler is None:\n",
    "            scaler = FunctionTransformer(lambda x: x)\n",
    "        else:\n",
    "            scaler = args.scaler()\n",
    "        init = True\n",
    "\n",
    "    num_chn = len(args.num_channels)\n",
    "\n",
    "    num_trials = data.shape[0]\n",
    "    data = data[:, ::int(1000 / args.sr_data), args.num_channels]\n",
    "    data = data[:, args.sample_rate[0]:args.sample_rate[1], :].reshape(-1, num_chn)\n",
    "\n",
    "    if init:\n",
    "        scaler.fit(data)\n",
    "    \n",
    "    data = scaler.transform(data)\n",
    "    data = data.reshape(num_trials, -1, num_chn)\n",
    "\n",
    "    # compute wavelet transform\n",
    "    if wavelet:\n",
    "        data = wavelet_transform(data, args)\n",
    "    data = data.reshape(num_trials, -1)\n",
    "\n",
    "    if init:\n",
    "        # fit lda model\n",
    "        lda.model.fit(data, target)\n",
    "        print(data.shape)\n",
    "\n",
    "    if target is not None:\n",
    "        # calculate accuracy\n",
    "        pred = lda.model.score(data, target)\n",
    "    else:\n",
    "        # predict probability of test data\n",
    "        pred = lda.model.predict_proba(data)\n",
    "\n",
    "    return pred, lda, scaler\n",
    "\n",
    "def real_time_predict(args, sock, basic_info, lda, scaler):\n",
    "    # start streaming\n",
    "    data, _ = request_data_packet(sock, basic_info)\n",
    "    num_samples = len(data) // (basic_info[\"data_size\"] * basic_info[\"eeg_chan\"])\n",
    "    SR = args.streaming_SR\n",
    "\n",
    "    events = {0: 'hungry',\n",
    "              1: 'tired',\n",
    "              2: 'thirsty',\n",
    "              3: 'toilet',\n",
    "              4: 'pain'}\n",
    "\n",
    "    segments = []\n",
    "    latencies = []\n",
    "    val_data = []\n",
    "    val_target = []\n",
    "    start_sample = 0\n",
    "    num_trials = 0\n",
    "    sample_count = SR + 1\n",
    "    restart = True\n",
    "    event_probs_list = []\n",
    "\n",
    "    while True:\n",
    "        data, message = request_data_packet(sock, basic_info, 1)\n",
    "\n",
    "        # check if data is dict\n",
    "        if isinstance(data, dict):\n",
    "            sample_count = 0\n",
    "            last_event = data['event_type']\n",
    "            last_latency = data['event_latency'] - start_sample\n",
    "        else:\n",
    "            # decode data to numpy\n",
    "            packet = decode_data(data, num_samples, basic_info)\n",
    "        \n",
    "            if restart:\n",
    "                restart = False\n",
    "                start_sample = message['start_sample']\n",
    "\n",
    "            segments.append(packet)\n",
    "            sample_count += 1\n",
    "\n",
    "        # if we have enough samples to make a trial\n",
    "        if sample_count == SR:\n",
    "            num_trials += 1\n",
    "            trial = np.concatenate(segments[-SR-1:], axis=0)\n",
    "\n",
    "            latency = int(last_latency - (len(segments) - SR - 1) * 1000 / SR)\n",
    "            val_data.append(trial[latency:latency+1000, :])\n",
    "            val_target.append(last_event - 2)\n",
    "            print(events[last_event-2])\n",
    "\n",
    "        # make a prediction after 4 trials\n",
    "        if num_trials == 4:\n",
    "            num_trials = 0\n",
    "            stop_stream(sock)\n",
    "        \n",
    "            # make a prediction\n",
    "            probs, _, _ = train_and_predict(args, np.array(val_data[-4:]), lda=lda, scaler=scaler, wavelet=args.wavelet)\n",
    "            event_probs_list.append(probs)\n",
    "\n",
    "            for p in probs:\n",
    "                # format to 2 decimals and sort by probability\n",
    "                event_probs = {events[j]: round(p[j], 2)*100 for j in events.keys()}\n",
    "\n",
    "                sorted_events = sorted(event_probs.items(),\n",
    "                                       key=lambda item: item[1],\n",
    "                                       reverse=True)\n",
    "                event_probs = {k: int(v) for k, v in sorted_events}\n",
    "                print(event_probs)\n",
    "\n",
    "            # press enter to continue or q to quit\n",
    "            key = input()\n",
    "            if key == 'q':\n",
    "                break\n",
    "            \n",
    "            # restart streaming\n",
    "            restart = True\n",
    "            segments = []\n",
    "            latencies = []\n",
    "\n",
    "            data, _ = request_data_packet(sock, basic_info)\n",
    "\n",
    "    return event_probs_list, val_data, val_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialise socket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TCP/IP socket\n",
    "sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "\n",
    "# Bind the socket to the port\n",
    "server_address = ('192.168.0.1', 4455)\n",
    "sock.connect(server_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'size': 24,\n",
       " 'eeg_chan': 69,\n",
       " 'sample_rate': 1000,\n",
       " 'data_size': 4,\n",
       " 'allow_client_to_control_amp': 0,\n",
       " 'allow_client_to_control_rec': 0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_info = client_get_basic_info(sock)\n",
    "basic_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1: 2 at 7285 ms\n",
      "Trial 2: 2 at 8375 ms\n",
      "Trial 3: 2 at 9464 ms\n",
      "Trial 4: 2 at 10554 ms\n",
      "Trial 5: 5 at 14914 ms\n",
      "Trial 6: 5 at 16004 ms\n",
      "Trial 7: 5 at 17094 ms\n",
      "Trial 8: 5 at 18184 ms\n",
      "Trial 9: 6 at 22613 ms\n",
      "Trial 10: 6 at 23703 ms\n",
      "Trial 11: 6 at 24793 ms\n",
      "Trial 12: 6 at 25883 ms\n",
      "Trial 13: 3 at 30393 ms\n",
      "Trial 14: 3 at 31483 ms\n",
      "Trial 15: 3 at 32572 ms\n",
      "Trial 16: 3 at 33662 ms\n",
      "Trial 17: 4 at 38092 ms\n",
      "Trial 18: 4 at 39182 ms\n",
      "Trial 19: 4 at 40272 ms\n",
      "Trial 20: 4 at 41362 ms\n",
      "Trial 21: 2 at 45531 ms\n",
      "Trial 22: 2 at 46621 ms\n",
      "Trial 23: 2 at 47711 ms\n",
      "Trial 24: 2 at 48801 ms\n",
      "Trial 25: 4 at 53101 ms\n",
      "Trial 26: 4 at 54191 ms\n",
      "Trial 27: 4 at 55281 ms\n",
      "Trial 28: 4 at 56370 ms\n",
      "Trial 29: 6 at 60770 ms\n",
      "Trial 30: 6 at 61860 ms\n",
      "Trial 31: 6 at 62950 ms\n",
      "Trial 32: 6 at 64040 ms\n",
      "Trial 33: 5 at 68449 ms\n",
      "Trial 34: 5 at 69539 ms\n",
      "Trial 35: 5 at 70629 ms\n",
      "Trial 36: 5 at 71719 ms\n",
      "Trial 37: 3 at 76109 ms\n",
      "Trial 38: 3 at 77199 ms\n",
      "Trial 39: 3 at 78289 ms\n",
      "Trial 40: 3 at 79378 ms\n",
      "Trial 41: 2 at 83578 ms\n",
      "Trial 42: 2 at 84668 ms\n",
      "Trial 43: 2 at 85758 ms\n",
      "Trial 44: 2 at 86848 ms\n",
      "Trial 45: 3 at 91158 ms\n",
      "Trial 46: 3 at 92247 ms\n",
      "Trial 47: 3 at 93337 ms\n",
      "Trial 48: 3 at 94427 ms\n",
      "Trial 49: 5 at 99007 ms\n",
      "Trial 50: 5 at 100097 ms\n",
      "Trial 51: 5 at 101187 ms\n",
      "Trial 52: 5 at 102277 ms\n",
      "Trial 53: 4 at 106586 ms\n",
      "Trial 54: 4 at 107676 ms\n",
      "Trial 55: 4 at 108766 ms\n",
      "Trial 56: 4 at 109856 ms\n",
      "Trial 57: 6 at 114326 ms\n",
      "Trial 58: 6 at 115415 ms\n",
      "Trial 59: 6 at 116505 ms\n",
      "Trial 60: 6 at 117595 ms\n",
      "Trial 61: 2 at 121895 ms\n",
      "Trial 62: 2 at 122985 ms\n",
      "Trial 63: 2 at 124075 ms\n",
      "Trial 64: 2 at 125165 ms\n",
      "Trial 65: 5 at 129554 ms\n",
      "Trial 66: 5 at 130644 ms\n",
      "Trial 67: 5 at 131734 ms\n",
      "Trial 68: 5 at 132824 ms\n",
      "Trial 69: 4 at 137154 ms\n",
      "Trial 70: 4 at 138243 ms\n",
      "Trial 71: 4 at 139333 ms\n",
      "Trial 72: 4 at 140423 ms\n",
      "Trial 73: 6 at 144793 ms\n",
      "Trial 74: 6 at 145883 ms\n",
      "Trial 75: 6 at 146973 ms\n",
      "Trial 76: 6 at 148063 ms\n",
      "Trial 77: 3 at 152402 ms\n",
      "Trial 78: 3 at 153492 ms\n",
      "Trial 79: 3 at 154582 ms\n",
      "Trial 80: 3 at 155672 ms\n",
      "Trial 81: 3 at 160082 ms\n",
      "Trial 82: 3 at 161172 ms\n",
      "Trial 83: 3 at 162261 ms\n",
      "Trial 84: 3 at 163351 ms\n",
      "Trial 85: 4 at 167691 ms\n",
      "Trial 86: 4 at 168781 ms\n",
      "Trial 87: 4 at 169871 ms\n",
      "Trial 88: 4 at 170961 ms\n",
      "Trial 89: 6 at 175230 ms\n",
      "Trial 90: 6 at 176320 ms\n",
      "Trial 91: 6 at 177410 ms\n",
      "Trial 92: 6 at 178500 ms\n",
      "Trial 93: 2 at 182920 ms\n",
      "Trial 94: 2 at 184010 ms\n",
      "Trial 95: 2 at 185100 ms\n",
      "Trial 96: 2 at 186189 ms\n",
      "Trial 97: 5 at 190599 ms\n",
      "Trial 98: 5 at 191689 ms\n",
      "Trial 99: 5 at 192779 ms\n",
      "Trial 100: 5 at 193869 ms\n",
      "Trial 101: 6 at 198258 ms\n",
      "Trial 102: 6 at 199348 ms\n",
      "Trial 103: 6 at 200438 ms\n",
      "Trial 104: 6 at 201528 ms\n",
      "Trial 105: 4 at 205738 ms\n",
      "Trial 106: 4 at 206828 ms\n",
      "Trial 107: 4 at 207918 ms\n",
      "Trial 108: 4 at 209007 ms\n",
      "Trial 109: 5 at 213337 ms\n",
      "Trial 110: 5 at 214427 ms\n",
      "Trial 111: 5 at 215517 ms\n",
      "Trial 112: 5 at 216607 ms\n",
      "Trial 113: 3 at 221176 ms\n",
      "Trial 114: 3 at 222266 ms\n",
      "Trial 115: 3 at 223356 ms\n",
      "Trial 116: 3 at 224446 ms\n",
      "Trial 117: 2 at 228986 ms\n",
      "Trial 118: 2 at 230076 ms\n",
      "Trial 119: 2 at 231166 ms\n",
      "Trial 120: 2 at 232256 ms\n",
      "Trial 121: 3 at 236685 ms\n",
      "Trial 122: 3 at 237775 ms\n",
      "Trial 123: 3 at 238865 ms\n",
      "Trial 124: 3 at 239955 ms\n",
      "Trial 125: 6 at 244404 ms\n",
      "Trial 126: 6 at 245494 ms\n",
      "Trial 127: 6 at 246584 ms\n",
      "Trial 128: 6 at 247674 ms\n",
      "Trial 129: 4 at 251884 ms\n",
      "Trial 130: 4 at 252974 ms\n",
      "Trial 131: 4 at 254064 ms\n",
      "Trial 132: 4 at 255154 ms\n",
      "Trial 133: 5 at 259773 ms\n",
      "Trial 134: 5 at 260863 ms\n",
      "Trial 135: 5 at 261953 ms\n",
      "Trial 136: 5 at 263043 ms\n",
      "Trial 137: 2 at 267413 ms\n",
      "Trial 138: 2 at 268502 ms\n",
      "Trial 139: 2 at 269592 ms\n",
      "Trial 140: 2 at 270682 ms\n",
      "Trial 141: 4 at 275182 ms\n",
      "Trial 142: 4 at 276272 ms\n",
      "Trial 143: 4 at 277362 ms\n",
      "Trial 144: 4 at 278452 ms\n",
      "Trial 145: 2 at 282701 ms\n",
      "Trial 146: 2 at 283791 ms\n",
      "Trial 147: 2 at 284881 ms\n",
      "Trial 148: 2 at 285971 ms\n",
      "Trial 149: 5 at 290371 ms\n",
      "Trial 150: 5 at 291461 ms\n",
      "Trial 151: 5 at 292550 ms\n",
      "Trial 152: 5 at 293640 ms\n",
      "Trial 153: 6 at 297910 ms\n",
      "Trial 154: 6 at 299000 ms\n",
      "Trial 155: 6 at 300090 ms\n",
      "Trial 156: 6 at 301180 ms\n",
      "Trial 157: 3 at 305459 ms\n",
      "Trial 158: 3 at 306549 ms\n",
      "Trial 159: 3 at 307639 ms\n",
      "Trial 160: 3 at 308729 ms\n",
      "Trial 161: 3 at 313199 ms\n",
      "Trial 162: 3 at 314289 ms\n",
      "Trial 163: 3 at 315378 ms\n",
      "Trial 164: 3 at 316468 ms\n",
      "Trial 165: 2 at 321008 ms\n",
      "Trial 166: 2 at 322098 ms\n",
      "Trial 167: 2 at 323188 ms\n",
      "Trial 168: 2 at 324278 ms\n",
      "Trial 169: 4 at 328777 ms\n",
      "Trial 170: 4 at 329867 ms\n",
      "Trial 171: 4 at 330957 ms\n",
      "Trial 172: 4 at 332047 ms\n",
      "Trial 173: 5 at 336447 ms\n",
      "Trial 174: 5 at 337537 ms\n",
      "Trial 175: 5 at 338626 ms\n",
      "Trial 176: 5 at 339716 ms\n",
      "Trial 177: 6 at 344116 ms\n",
      "Trial 178: 6 at 345206 ms\n",
      "Trial 179: 6 at 346296 ms\n",
      "Trial 180: 6 at 347386 ms\n",
      "Trial 181: 2 at 351785 ms\n",
      "Trial 182: 2 at 352875 ms\n",
      "Trial 183: 2 at 353965 ms\n",
      "Trial 184: 2 at 355055 ms\n",
      "Trial 185: 6 at 359425 ms\n",
      "Trial 186: 6 at 360515 ms\n",
      "Trial 187: 6 at 361605 ms\n",
      "Trial 188: 6 at 362694 ms\n",
      "Trial 189: 3 at 367064 ms\n",
      "Trial 190: 3 at 368154 ms\n",
      "Trial 191: 3 at 369244 ms\n",
      "Trial 192: 3 at 370334 ms\n",
      "Trial 193: 5 at 374713 ms\n",
      "Trial 194: 5 at 375803 ms\n",
      "Trial 195: 5 at 376893 ms\n",
      "Trial 196: 5 at 377983 ms\n",
      "Trial 197: 4 at 382453 ms\n",
      "Trial 198: 4 at 383543 ms\n",
      "Trial 199: 4 at 384633 ms\n",
      "Trial 200: 4 at 385723 ms\n",
      "Trial 201: 3 at 389982 ms\n",
      "Trial 202: 3 at 391072 ms\n",
      "Trial 203: 3 at 392162 ms\n",
      "Trial 204: 3 at 393252 ms\n",
      "Trial 205: 2 at 397811 ms\n",
      "Trial 206: 2 at 398901 ms\n",
      "Trial 207: 2 at 399991 ms\n",
      "Trial 208: 2 at 401081 ms\n",
      "Trial 209: 6 at 405521 ms\n",
      "Trial 210: 6 at 406611 ms\n",
      "Trial 211: 6 at 407701 ms\n",
      "Trial 212: 6 at 408791 ms\n",
      "Trial 213: 4 at 413210 ms\n",
      "Trial 214: 4 at 414300 ms\n",
      "Trial 215: 4 at 415390 ms\n",
      "Trial 216: 4 at 416480 ms\n",
      "Trial 217: 5 at 420860 ms\n",
      "Trial 218: 5 at 421949 ms\n",
      "Trial 219: 5 at 423039 ms\n",
      "Trial 220: 5 at 424129 ms\n",
      "Trial 221: 2 at 428419 ms\n",
      "Trial 222: 2 at 429509 ms\n",
      "Trial 223: 2 at 430599 ms\n",
      "Trial 224: 2 at 431689 ms\n",
      "Trial 225: 3 at 436028 ms\n",
      "Trial 226: 3 at 437118 ms\n",
      "Trial 227: 3 at 438208 ms\n",
      "Trial 228: 3 at 439298 ms\n",
      "Trial 229: 5 at 443708 ms\n",
      "Trial 230: 5 at 444797 ms\n",
      "Trial 231: 5 at 445887 ms\n",
      "Trial 232: 5 at 446977 ms\n",
      "Trial 233: 4 at 451417 ms\n",
      "Trial 234: 4 at 452507 ms\n",
      "Trial 235: 4 at 453597 ms\n",
      "Trial 236: 4 at 454687 ms\n",
      "Trial 237: 6 at 459246 ms\n",
      "Trial 238: 6 at 460336 ms\n",
      "Trial 239: 6 at 461426 ms\n",
      "Trial 240: 6 at 462516 ms\n",
      "Trial 241: 2 at 466946 ms\n",
      "Trial 242: 2 at 468036 ms\n",
      "Trial 243: 2 at 469125 ms\n",
      "Trial 244: 2 at 470215 ms\n",
      "Trial 245: 3 at 474565 ms\n",
      "Trial 246: 3 at 475655 ms\n",
      "Trial 247: 3 at 476745 ms\n",
      "Trial 248: 3 at 477835 ms\n",
      "Trial 249: 5 at 482224 ms\n",
      "Trial 250: 5 at 483314 ms\n",
      "Trial 251: 5 at 484404 ms\n",
      "Trial 252: 5 at 485494 ms\n",
      "Trial 253: 4 at 489874 ms\n",
      "Trial 254: 4 at 490964 ms\n",
      "Trial 255: 4 at 492054 ms\n",
      "Trial 256: 4 at 493143 ms\n",
      "Trial 257: 6 at 497743 ms\n",
      "Trial 258: 6 at 498833 ms\n",
      "Trial 259: 6 at 499923 ms\n",
      "Trial 260: 6 at 501013 ms\n",
      "Trial 261: 2 at 505322 ms\n",
      "Trial 262: 2 at 506412 ms\n",
      "Trial 263: 2 at 507502 ms\n",
      "Trial 264: 2 at 508592 ms\n",
      "Trial 265: 6 at 513072 ms\n",
      "Trial 266: 6 at 514162 ms\n",
      "Trial 267: 6 at 515251 ms\n",
      "Trial 268: 6 at 516341 ms\n",
      "Trial 269: 3 at 520731 ms\n",
      "Trial 270: 3 at 521821 ms\n",
      "Trial 271: 3 at 522911 ms\n",
      "Trial 272: 3 at 524001 ms\n",
      "Trial 273: 5 at 528330 ms\n",
      "Trial 274: 5 at 529420 ms\n",
      "Trial 275: 5 at 530510 ms\n",
      "Trial 276: 5 at 531600 ms\n",
      "Trial 277: 4 at 535940 ms\n",
      "Trial 278: 4 at 537030 ms\n",
      "Trial 279: 4 at 538120 ms\n",
      "Trial 280: 4 at 539209 ms\n"
     ]
    }
   ],
   "source": [
    "segments, events, train_data, train_target = get_initial_data(sock,\n",
    "                                                              basic_info,\n",
    "                                                              args.streaming_SR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "save_data(args, segments, events, train_data, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking data\n",
    "cont_segments = segments.transpose(2, 0, 1).reshape(69, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notch filter data at 50Hz and harmonics\n",
    "cont_segments = notch_filter(cont_segments, 1000, 49)\n",
    "cont_segments = notch_filter(cont_segments, 1000, 99)\n",
    "cont_segments = notch_filter(cont_segments, 1000, 149)\n",
    "cont_segments = notch_filter(cont_segments, 1000, 199)\n",
    "cont_segments = notch_filter(cont_segments, 1000, 249)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    2,  7285],\n",
       "       [    2,  8375],\n",
       "       [    2,  9464],\n",
       "       [    2, 10554],\n",
       "       [    5, 14914],\n",
       "       [    5, 16004],\n",
       "       [    5, 17094],\n",
       "       [    5, 18184],\n",
       "       [    6, 22613],\n",
       "       [    6, 23703]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c70a09dfcf6f4d84a2d138e92ed3c26f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "plt.plot(cont_segments[-1, :30000])\n",
    "e=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9837c38f80d4aa8b4fe3e286b9044e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Frequency (Hz)')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "# compute PSD for each channel\n",
    "f, psd = welch(cont_segments[[0, 1, 2, 64, 65, 66]], fs=1000, nperseg=8000, noverlap=4000)\n",
    "\n",
    "# plot PSD\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(f, psd.T)\n",
    "\n",
    "plt.xlim(3, 250)\n",
    "plt.ylim(0, 20)\n",
    "plt.xlabel('Frequency (Hz)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_segments = cont_segments[:, ::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "179a8d89c6c64613802e6fc952040ccd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot spectogram of cont_segments\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.specgram(cont_segments[2, 5000:5500], Fs=500, NFFT=32, noverlap=31)\n",
    "e=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c41d7945f12a4faf834a03407074ff80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd18145cd60>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "plt.plot(cont_segments[[3], 20000:40000].T, linewidth=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abb6166a213547b78a61f488468dba08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9c1a70e460>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check evoked responses\n",
    "%matplotlib widget\n",
    "plt.plot(train_data[train_target==2, :, 64].mean(axis=0), linewidth=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resegment data using events\n",
    "train_data, train_target = resegment_data(cont_segments, events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(280, 1000, 69)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dbdd9aea71e4e0696d8d3441dc23b62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot spectogram of cont_segments\n",
    "%matplotlib widget\n",
    "# set log y scale\n",
    "plt.specgram(train_data[50, ::2, 2], Fs=500, NFFT=25, noverlap=24, scale='dB')\n",
    "e=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train_data = np.load(os.path.join(args.result_dir, 'train_data.npy'))\n",
    "train_target = np.load(os.path.join(args.result_dir, 'train_target.npy'))\n",
    "\n",
    "segments = np.load(os.path.join(args.result_dir, 'segments.npy'))\n",
    "events = np.load(os.path.join(args.result_dir, 'events.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.num_channels = [0, 1, 2, 64, 65, 66]  # 2, 64, 65 / 0, 1, 2, 64, 65, 66\n",
    "args.halfwin = 8  # 10 / 10\n",
    "args.overlap = 4 # 5 / 2\n",
    "args.C_reg = 0.05 # 0.5\n",
    "args.model = LDA # LDA / LogisticRegL1\n",
    "args.scaler = StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't load conv model for lda.\n",
      "(280, 2268)\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# train on training split\n",
    "ntrials = 280\n",
    "acc, lda, scaler = train_and_predict(\n",
    "    args, train_data[:ntrials], train_target[:ntrials], wavelet=True)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "# test on validation split\n",
    "acc, _, _ = train_and_predict(\n",
    "    args, train_data[ntrials:], train_target[ntrials:], lda=lda, scaler=scaler, wavelet=False)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize hyperparams\n",
    "C_reg = [0.05, 0.1, 1, 2, 10]\n",
    "halfwin = [5, 7, 9, 11, 13, 15]\n",
    "overlap = [1, 3, 5, 7]\n",
    "num_channels = [[0, 1, 2, 64, 65, 66]]\n",
    "scalers = [StandardScaler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize hyperparams\n",
    "C_reg = [0.1, 1, 10]\n",
    "halfwin = [8]\n",
    "overlap = [4]\n",
    "num_channels = [[2, 64]]\n",
    "pca_comps = [0]\n",
    "scalers = [RobustScaler]\n",
    "wavelet = [False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END halfwin=8, num_channels=[2, 64], overlap=4, scaler=<class 'sklearn.preprocessing._data.RobustScaler'>;, score=0.500 total time=   0.7s\n",
      "[CV 3/5] END halfwin=8, num_channels=[2, 64], overlap=4, scaler=<class 'sklearn.preprocessing._data.RobustScaler'>;, score=0.423 total time=   0.7s\n",
      "[CV 4/5] END halfwin=8, num_channels=[2, 64], overlap=4, scaler=<class 'sklearn.preprocessing._data.RobustScaler'>;, score=0.404 total time=   0.7s\n",
      "[CV 5/5] END halfwin=8, num_channels=[2, 64], overlap=4, scaler=<class 'sklearn.preprocessing._data.RobustScaler'>;, score=0.462 total time=   0.7s\n",
      "[CV 2/5] END halfwin=8, num_channels=[2, 64], overlap=4, scaler=<class 'sklearn.preprocessing._data.RobustScaler'>;, score=0.404 total time=   0.7s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LDATune(), n_jobs=-1,\n",
       "             param_grid={'halfwin': [8], 'num_channels': [[2, 64]],\n",
       "                         'overlap': [4],\n",
       "                         'scaler': [<class 'sklearn.preprocessing._data.RobustScaler'>]},\n",
       "             scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridCV = GridSearchCV(estimator=LDATune(),\n",
    "                      param_grid={\n",
    "                                  'halfwin': halfwin,\n",
    "                                  'overlap': overlap,\n",
    "                                  'num_channels': num_channels,\n",
    "                                  'scaler': scalers},\n",
    "                      scoring='accuracy',\n",
    "                      n_jobs=-1,\n",
    "                      verbose=3)\n",
    "ntrials = 260\n",
    "gridCV.fit(train_data[:ntrials], train_target[:ntrials])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegTune(C=1, halfwin=15, overlap=1,\n",
      "                scaler=<class 'sklearn.preprocessing._data.StandardScaler'>)\n",
      "0.6807692307692308\n"
     ]
    }
   ],
   "source": [
    "print(gridCV.best_estimator_)\n",
    "print(gridCV.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9192307692307692\n",
      "0.55\n"
     ]
    }
   ],
   "source": [
    "ntrials = 260\n",
    "best_model = LogisticRegTune(C=1, halfwin=15, overlap=1, num_channels=[0, 1, 2, 64, 65, 66], scaler=StandardScaler)\n",
    "best_model.fit(train_data[:ntrials], train_target[:ntrials])\n",
    "print(best_model.score(train_data[:ntrials], train_target[:ntrials]))\n",
    "print(best_model.score(train_data[ntrials:], train_target[ntrials:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9961538461538462\n",
      "0.65\n"
     ]
    }
   ],
   "source": [
    "ntrials = 260\n",
    "best_model = LDATune(halfwin=8, overlap=4, num_channels=[0, 1, 2, 64, 65, 66], scaler=StandardScaler, wavelet=True)\n",
    "best_model.fit(train_data[:ntrials], train_target[:ntrials])\n",
    "print(best_model.score(train_data[:ntrials], train_target[:ntrials]))\n",
    "print(best_model.score(train_data[ntrials:], train_target[ntrials:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Closed-loop prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_data = [train_data]\n",
    "overall_target = [train_target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extend overall lists\n",
    "overall_data.append(val_data)\n",
    "overall_target.append(val_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't load conv model for lda.\n",
      "(596, 2268)\n",
      "0.9630872483221476\n"
     ]
    }
   ],
   "source": [
    "# retrain on overall data\n",
    "acc, lda, scaler = train_and_predict(\n",
    "    args, np.concatenate(overall_data, axis=0), np.concatenate(overall_target, axis=0), wavelet=True)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thirsty\n",
      "thirsty\n",
      "thirsty\n",
      "thirsty\n",
      "{'thirsty': 90, 'pain': 10, 'hungry': 0, 'tired': 0, 'toilet': 0}\n",
      "{'toilet': 100, 'hungry': 0, 'tired': 0, 'thirsty': 0, 'pain': 0}\n",
      "{'thirsty': 100, 'hungry': 0, 'tired': 0, 'toilet': 0, 'pain': 0}\n",
      "{'toilet': 100, 'hungry': 0, 'tired': 0, 'thirsty': 0, 'pain': 0}\n",
      "tired\n",
      "tired\n",
      "tired\n",
      "tired\n",
      "{'pain': 100, 'hungry': 0, 'tired': 0, 'thirsty': 0, 'toilet': 0}\n",
      "{'pain': 83, 'toilet': 13, 'tired': 5, 'hungry': 0, 'thirsty': 0}\n",
      "{'tired': 100, 'hungry': 0, 'thirsty': 0, 'toilet': 0, 'pain': 0}\n",
      "{'pain': 100, 'hungry': 0, 'tired': 0, 'thirsty': 0, 'toilet': 0}\n",
      "toilet\n",
      "toilet\n",
      "toilet\n",
      "toilet\n",
      "{'pain': 100, 'hungry': 0, 'tired': 0, 'thirsty': 0, 'toilet': 0}\n",
      "{'pain': 48, 'toilet': 37, 'tired': 15, 'hungry': 0, 'thirsty': 0}\n",
      "{'toilet': 100, 'hungry': 0, 'tired': 0, 'thirsty': 0, 'pain': 0}\n",
      "{'toilet': 100, 'hungry': 0, 'tired': 0, 'thirsty': 0, 'pain': 0}\n",
      "thirsty\n",
      "thirsty\n",
      "thirsty\n",
      "thirsty\n",
      "{'thirsty': 100, 'hungry': 0, 'tired': 0, 'toilet': 0, 'pain': 0}\n",
      "{'thirsty': 100, 'hungry': 0, 'tired': 0, 'toilet': 0, 'pain': 0}\n",
      "{'pain': 99, 'tired': 1, 'hungry': 0, 'thirsty': 0, 'toilet': 0}\n",
      "{'thirsty': 100, 'hungry': 0, 'tired': 0, 'toilet': 0, 'pain': 0}\n"
     ]
    }
   ],
   "source": [
    "args.wavelet = True\n",
    "probs_list, val_data, val_target = real_time_predict(args, sock, basic_info, lda, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to array\n",
    "probs = np.array(probs_list)\n",
    "val_data = np.array(val_data)\n",
    "val_target = np.array(val_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save probs list and val_data and val_target\n",
    "np.save(os.path.join(args.result_dir, 'probs_list_silent7.npy'), probs)\n",
    "np.save(os.path.join(args.result_dir, 'val_data_silent7.npy'), val_data)\n",
    "np.save(os.path.join(args.result_dir, 'val_target_silent7.npy'), val_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load probs list and val_data and val_target\n",
    "probs = np.load(os.path.join(args.result_dir, 'probs_list_loud4.npy'))\n",
    "val_data = np.load(os.path.join(args.result_dir, 'val_data_loud4.npy'))\n",
    "val_target = np.load(os.path.join(args.result_dir, 'val_target_loud4.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 3, 3, 3, 3, 2, 2, 2, 2, 3, 3, 3, 3, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 4, 4, 4, 4, 2, 2, 2, 2, 1, 1, 1, 1, 3, 3, 3, 3, 4, 4, 4, 4])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 3, 1, 0, 1, 3, 3, 1, 4, 2, 2, 1, 1, 3, 3, 0, 1, 3, 2, 0, 1,\n",
       "       1, 1, 0, 4, 2, 2, 2, 1, 2, 1, 4, 1, 1, 1, 1, 3, 3, 3, 1, 2, 0, 3])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(probs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate accuracy\n",
    "probs = probs.reshape(-1, probs.shape[2])\n",
    "acc = np.mean(np.argmax(probs, axis=1) == val_target)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45454545454545453\n"
     ]
    }
   ],
   "source": [
    "acc, _, _ = train_and_predict(\n",
    "    args, val_data, val_target, lda=lda, scaler=scaler, wavelet=True)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extend overall lists\n",
    "overall_data.append(val_data)\n",
    "overall_target.append(val_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't load conv model for lda.\n",
      "(404, 2268)\n",
      "0.9876237623762376\n"
     ]
    }
   ],
   "source": [
    "# retrain on overall data\n",
    "acc, lda, scaler = train_and_predict(\n",
    "    args, np.concatenate(overall_data, axis=0), np.concatenate(overall_target, axis=0), wavelet=True)\n",
    "print(acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('main')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3818df9f0fda158f80d2404c4b51c3eecd7a0fbc4149212a6ea8c0c98c2a56f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
