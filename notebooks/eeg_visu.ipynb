{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import mne\n",
    "import osl\n",
    "import yaml\n",
    "import pickle\n",
    "from scipy.io import savemat\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "# import distance_riemann\n",
    "from pyriemann.utils.distance import distance_riemann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# closest 1 for eeg data\n",
    "a = np.arange(53).reshape(-1, 1)\n",
    "pickle.dump(a, open('eeg_closest1', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rem = ['F7', 'F2', 'F4', 'F6', 'FT9', 'T9', 'P4', 'OZ',\n",
    "        'F3', 'P1', 'PO7', 'PO3', 'PO4', 'PO8', 'O1', 'O2']\n",
    "\n",
    "# print indices of channels not to remove\n",
    "print([i for i, ch in enumerate(epochs[0].info['ch_names']) if ch not in rem])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file /gpfs2/well/woolrich/projects/disp_csaky/eeg/session2/preproc1_20hz_noica/oslpy/preproc_preproc_raw.fif...\n",
      "    Range : 0 ... 3068699 =      0.000 ...  3068.699 secs\n",
      "Ready.\n",
      "Reading 0 ... 3068699  =      0.000 ...  3068.699 secs...\n",
      "Opening raw data file /gpfs2/well/woolrich/projects/disp_csaky/eeg/session3/preproc1_20hz_noica/oslpy/preproc_preproc_raw.fif...\n",
      "    Range : 0 ... 2754699 =      0.000 ...  2754.699 secs\n",
      "Ready.\n",
      "Reading 0 ... 2754699  =      0.000 ...  2754.699 secs...\n",
      "Opening raw data file /gpfs2/well/woolrich/projects/disp_csaky/eeg/session4/preproc1_20hz_noica/oslpy/preproc_preproc_raw.fif...\n",
      "    Range : 0 ... 2758099 =      0.000 ...  2758.099 secs\n",
      "Ready.\n",
      "Reading 0 ... 2758099  =      0.000 ...  2758.099 secs...\n",
      "Opening raw data file /gpfs2/well/woolrich/projects/disp_csaky/eeg/session5/preproc1_20hz_noica/oslpy/preproc_preproc_raw.fif...\n",
      "    Range : 0 ... 2786699 =      0.000 ...  2786.699 secs\n",
      "Ready.\n",
      "Reading 0 ... 2786699  =      0.000 ...  2786.699 secs...\n",
      "Opening raw data file /gpfs2/well/woolrich/projects/disp_csaky/eeg/session6/preproc1_20hz_noica/oslpy/preproc_preproc_raw.fif...\n",
      "    Range : 0 ... 2769299 =      0.000 ...  2769.299 secs\n",
      "Ready.\n",
      "Reading 0 ... 2769299  =      0.000 ...  2769.299 secs...\n",
      "Opening raw data file /gpfs2/well/woolrich/projects/disp_csaky/eeg/session7/preproc1_20hz_noica/oslpy/preproc_preproc_raw.fif...\n",
      "    Range : 0 ... 2738499 =      0.000 ...  2738.499 secs\n",
      "Ready.\n",
      "Reading 0 ... 2738499  =      0.000 ...  2738.499 secs...\n",
      "Opening raw data file /gpfs2/well/woolrich/projects/disp_csaky/eeg/session8/preproc1_20hz_noica/oslpy/preproc_preproc_raw.fif...\n",
      "    Range : 0 ... 3208899 =      0.000 ...  3208.899 secs\n",
      "Ready.\n",
      "Reading 0 ... 3208899  =      0.000 ...  3208.899 secs...\n",
      "Opening raw data file /gpfs2/well/woolrich/projects/disp_csaky/eeg/session9/preproc1_20hz_noica/oslpy/preproc_preproc_raw.fif...\n",
      "    Range : 0 ... 2829399 =      0.000 ...  2829.399 secs\n",
      "Ready.\n",
      "Reading 0 ... 2829399  =      0.000 ...  2829.399 secs...\n",
      "Opening raw data file /gpfs2/well/woolrich/projects/disp_csaky/eeg/session10/preproc1_20hz_noica/oslpy/preproc_preproc_raw.fif...\n",
      "    Range : 0 ... 2866899 =      0.000 ...  2866.899 secs\n",
      "Ready.\n",
      "Reading 0 ... 2866899  =      0.000 ...  2866.899 secs...\n",
      "Opening raw data file /gpfs2/well/woolrich/projects/disp_csaky/eeg/session11/preproc1_20hz_noica/oslpy/preproc_preproc_raw.fif...\n",
      "    Range : 0 ... 2789799 =      0.000 ...  2789.799 secs\n",
      "Ready.\n",
      "Reading 0 ... 2789799  =      0.000 ...  2789.799 secs...\n"
     ]
    }
   ],
   "source": [
    "raws = []\n",
    "\n",
    "for i in range(2, 12):\n",
    "    sid = str(i)\n",
    "    fif_name = \"preproc_preproc_raw.fif\"\n",
    "    base = \"/gpfs2/well/woolrich/projects/disp_csaky/eeg/\"\n",
    "    dataset_path = base + f\"session{sid}/preproc1_20hz_noica/oslpy/\" + fif_name\n",
    "\n",
    "    # load raw data\n",
    "    raws.append(mne.io.read_raw_fif(dataset_path, preload=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'AF4': 10, 'AF8': 10, 'AFZ': 9, 'AF3': 7, 'FP1': 6, 'AF7': 4, 'FP2': 3, 'Fz': 3, 'FT10': 2, 'FPZ': 1, 'F8': 1, 'FT7': 1, 'O1': 1, 'OZ': 1, 'FT9': 1})\n"
     ]
    }
   ],
   "source": [
    "bads = Counter()\n",
    "for raw in raws:\n",
    "    bads.update(raw.info['bads'])\n",
    "print(bads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FP1', 'FP2', 'AF3', 'AFZ', 'AF4', 'AF8', 'Fz', 'AF7', 'FT10']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_channels = [ch for ch, count in bads.items() if count > 1]\n",
    "bad_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raws = [raw.drop_channels(bad_channels) for raw in raws]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting existing file.\n",
      "Writing /gpfs2/well/woolrich/projects/disp_csaky/eeg/session2/preproc1_20hz_noica/oslpy/preproc_preproc_raw.fif\n",
      "Closing /gpfs2/well/woolrich/projects/disp_csaky/eeg/session2/preproc1_20hz_noica/oslpy/preproc_preproc_raw.fif\n",
      "[done]\n",
      "Overwriting existing file.\n",
      "Writing /gpfs2/well/woolrich/projects/disp_csaky/eeg/session3/preproc1_20hz_noica/oslpy/preproc_preproc_raw.fif\n",
      "Closing /gpfs2/well/woolrich/projects/disp_csaky/eeg/session3/preproc1_20hz_noica/oslpy/preproc_preproc_raw.fif\n",
      "[done]\n",
      "Overwriting existing file.\n",
      "Writing /gpfs2/well/woolrich/projects/disp_csaky/eeg/session4/preproc1_20hz_noica/oslpy/preproc_preproc_raw.fif\n",
      "Closing /gpfs2/well/woolrich/projects/disp_csaky/eeg/session4/preproc1_20hz_noica/oslpy/preproc_preproc_raw.fif\n",
      "[done]\n",
      "Overwriting existing file.\n",
      "Writing /gpfs2/well/woolrich/projects/disp_csaky/eeg/session5/preproc1_20hz_noica/oslpy/preproc_preproc_raw.fif\n",
      "Closing /gpfs2/well/woolrich/projects/disp_csaky/eeg/session5/preproc1_20hz_noica/oslpy/preproc_preproc_raw.fif\n",
      "[done]\n",
      "Overwriting existing file.\n",
      "Writing /gpfs2/well/woolrich/projects/disp_csaky/eeg/session6/preproc1_20hz_noica/oslpy/preproc_preproc_raw.fif\n",
      "Closing /gpfs2/well/woolrich/projects/disp_csaky/eeg/session6/preproc1_20hz_noica/oslpy/preproc_preproc_raw.fif\n",
      "[done]\n",
      "Overwriting existing file.\n",
      "Writing /gpfs2/well/woolrich/projects/disp_csaky/eeg/session7/preproc1_20hz_noica/oslpy/preproc_preproc_raw.fif\n",
      "Closing /gpfs2/well/woolrich/projects/disp_csaky/eeg/session7/preproc1_20hz_noica/oslpy/preproc_preproc_raw.fif\n",
      "[done]\n",
      "Overwriting existing file.\n",
      "Writing /gpfs2/well/woolrich/projects/disp_csaky/eeg/session8/preproc1_20hz_noica/oslpy/preproc_preproc_raw.fif\n",
      "Closing /gpfs2/well/woolrich/projects/disp_csaky/eeg/session8/preproc1_20hz_noica/oslpy/preproc_preproc_raw.fif\n",
      "[done]\n",
      "Overwriting existing file.\n",
      "Writing /gpfs2/well/woolrich/projects/disp_csaky/eeg/session9/preproc1_20hz_noica/oslpy/preproc_preproc_raw.fif\n",
      "Closing /gpfs2/well/woolrich/projects/disp_csaky/eeg/session9/preproc1_20hz_noica/oslpy/preproc_preproc_raw.fif\n",
      "[done]\n",
      "Overwriting existing file.\n",
      "Writing /gpfs2/well/woolrich/projects/disp_csaky/eeg/session10/preproc1_20hz_noica/oslpy/preproc_preproc_raw.fif\n",
      "Closing /gpfs2/well/woolrich/projects/disp_csaky/eeg/session10/preproc1_20hz_noica/oslpy/preproc_preproc_raw.fif\n",
      "[done]\n",
      "Overwriting existing file.\n",
      "Writing /gpfs2/well/woolrich/projects/disp_csaky/eeg/session11/preproc1_20hz_noica/oslpy/preproc_preproc_raw.fif\n",
      "Closing /gpfs2/well/woolrich/projects/disp_csaky/eeg/session11/preproc1_20hz_noica/oslpy/preproc_preproc_raw.fif\n",
      "[done]\n"
     ]
    }
   ],
   "source": [
    "# save raws\n",
    "for i in range(2, 12):\n",
    "    sid = str(i)\n",
    "    fif_name = \"preproc_preproc_raw.fif\"\n",
    "    base = \"/gpfs2/well/woolrich/projects/disp_csaky/eeg/\"\n",
    "    dataset_path = base + f\"session{sid}/preproc1_20hz_noica/oslpy/\" + fif_name\n",
    "\n",
    "    # save raw data\n",
    "    raws[i-2].save(dataset_path, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raws[0].plot_sensors(ch_type='eeg', kind='topomap', show_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "raws[0].plot(n_channels=30, duration=50)\n",
    "e=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['11', '12', '13', '14', '15', '2', '3', '4', '5', '6', '7', '8']\n",
      "176\n",
      "162\n",
      "Not setting metadata\n",
      "1352 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1352 events and 2001 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-d163d16fc5e5>:69: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  ep = mne.Epochs(raw,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142 bad epochs dropped\n",
      "Used Annotations descriptions: ['11', '12', '13', '14', '15', '2', '3', '4', '5', '6', '7', '8']\n",
      "error1\n",
      "178\n",
      "162\n",
      "Not setting metadata\n",
      "1356 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1356 events and 2001 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-d163d16fc5e5>:69: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  ep = mne.Epochs(raw,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213 bad epochs dropped\n",
      "Used Annotations descriptions: ['11', '12', '13', '14', '15', '2', '3', '4', '5', '6', '7', '8']\n",
      "179\n",
      "162\n",
      "Not setting metadata\n",
      "1364 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1364 events and 2001 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-d163d16fc5e5>:69: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  ep = mne.Epochs(raw,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149 bad epochs dropped\n",
      "Used Annotations descriptions: ['10', '11', '12', '13', '14', '15', '2', '3', '4', '5', '6', '7', '8']\n",
      "182\n",
      "160\n",
      "Not setting metadata\n",
      "1368 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1368 events and 2001 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-d163d16fc5e5>:69: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  ep = mne.Epochs(raw,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189 bad epochs dropped\n",
      "Used Annotations descriptions: ['10', '11', '12', '13', '14', '15', '2', '3', '4', '5', '6', '7', '8']\n",
      "177\n",
      "161\n",
      "Not setting metadata\n",
      "1352 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1352 events and 2001 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-d163d16fc5e5>:69: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  ep = mne.Epochs(raw,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 bad epochs dropped\n",
      "Used Annotations descriptions: ['10', '11', '12', '13', '14', '15', '2', '3', '4', '5', '6', '7', '8']\n",
      "183\n",
      "160\n",
      "Not setting metadata\n",
      "1372 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1372 events and 2001 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-d163d16fc5e5>:69: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  ep = mne.Epochs(raw,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 bad epochs dropped\n",
      "Used Annotations descriptions: ['11', '12', '13', '14', '15', '2', '3', '4', '5', '6', '7', '8']\n",
      "183\n",
      "162\n",
      "Not setting metadata\n",
      "1380 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1380 events and 2001 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-d163d16fc5e5>:69: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  ep = mne.Epochs(raw,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139 bad epochs dropped\n",
      "Used Annotations descriptions: ['11', '12', '13', '14', '15', '2', '3', '4', '5', '6', '7', '8']\n",
      "189\n",
      "162\n",
      "Not setting metadata\n",
      "1404 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1404 events and 2001 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-d163d16fc5e5>:69: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  ep = mne.Epochs(raw,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154 bad epochs dropped\n",
      "Used Annotations descriptions: ['11', '12', '13', '14', '15', '2', '3', '4', '5', '6', '7', '8']\n",
      "177\n",
      "162\n",
      "Not setting metadata\n",
      "1356 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1356 events and 2001 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-d163d16fc5e5>:69: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  ep = mne.Epochs(raw,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107 bad epochs dropped\n",
      "Used Annotations descriptions: ['10', '11', '12', '13', '14', '15', '2', '3', '4', '5', '6', '7', '8']\n",
      "188\n",
      "161\n",
      "Not setting metadata\n",
      "1396 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1396 events and 2001 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-d163d16fc5e5>:69: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  ep = mne.Epochs(raw,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "# find epochs specific to words\n",
    "event_id = {'2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '10': 10, '11': 11, '12': 12, '13': 13, '14': 14, '15': 15}\n",
    "epoch_event_id = {'words/hungry': 2, 'words/thirst': 3, 'words/tired': 4, 'words/toilet': 5, 'words/pain': 6}\n",
    "\n",
    "epochs = []\n",
    "for raw in raws:\n",
    "    events = mne.events_from_annotations(raw, event_id=event_id)\n",
    "\n",
    "    event_c = np.array([e[2] for e in events[0]])\n",
    "    event_t = np.array([e[0] for e in events[0]])\n",
    "\n",
    "    count1 = 0\n",
    "    count2 = 0\n",
    "    new_events = []\n",
    "    for i, (et, ec) in enumerate(zip(event_t, event_c)):\n",
    "        if ec < 7 and ec > 1:\n",
    "            count1 += 1\n",
    "            if event_c[i+1] == 8:\n",
    "                new_events.append(np.array([event_t[i+1], 0, ec]))\n",
    "            else:\n",
    "                print('error1')\n",
    "                continue\n",
    "            if event_c[i+2] == 8:\n",
    "                new_events.append(np.array([event_t[i+2], 0, ec]))\n",
    "            else:\n",
    "                print('error2')\n",
    "            if event_c[i+3] == 8:\n",
    "                new_events.append(np.array([event_t[i+3], 0, ec]))\n",
    "            else:\n",
    "                print('error3')\n",
    "            if event_c[i+4] == 8:\n",
    "                new_events.append(np.array([event_t[i+4], 0, ec]))\n",
    "            else:\n",
    "                print('error4')\n",
    "\n",
    "        elif ec < 16 and ec > 10:\n",
    "            count2 += 1\n",
    "            split_events = event_c[i-18:i-4]\n",
    "            #print(split_events)\n",
    "            tind = np.nonzero(split_events == 7)[0][-1]\n",
    "\n",
    "            tind += i-18\n",
    "\n",
    "            if event_c[tind+1] == 8:\n",
    "                new_events.append(np.array([event_t[tind+1], 0, ec-9]))\n",
    "            else:\n",
    "                print('erorr5')\n",
    "                print(event_c[i-20:i])\n",
    "            if event_c[tind+2] == 8:\n",
    "                new_events.append(np.array([event_t[tind+2], 0, ec-9]))\n",
    "            else:\n",
    "                print('erorr6')\n",
    "                print(event_c[i-20:i])\n",
    "            if event_c[tind+3] == 8:\n",
    "                new_events.append(np.array([event_t[tind+3], 0, ec-9]))\n",
    "            else:\n",
    "                print('erorr7')\n",
    "            if event_c[tind+4] == 8:\n",
    "                new_events.append(np.array([event_t[tind+4], 0, ec-9]))\n",
    "            else:\n",
    "                print('erorr8')\n",
    "\n",
    "\n",
    "    print(count1)\n",
    "    print(count2)\n",
    "\n",
    "    new_events = np.array(new_events)\n",
    "\n",
    "    ep = mne.Epochs(raw,\n",
    "                    new_events,\n",
    "                    event_id=epoch_event_id,\n",
    "                    tmin=-1,\n",
    "                    tmax=1,\n",
    "                    baseline=None,\n",
    "                    picks=['eeg'],\n",
    "                    reject=None,\n",
    "                    preload=True)\n",
    "    epochs.append(ep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find epochs specific to words\n",
    "event_id = {'2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '10': 10, '11': 11, '12': 12, '13': 13, '14': 14, '15': 15}\n",
    "epoch_event_id = {'words/hungry': 2, 'words/thirst': 3, 'words/tired': 4, 'words/toilet': 5, 'words/pain': 6}\n",
    "\n",
    "epochs = []\n",
    "for raw in raws:\n",
    "    events = mne.events_from_annotations(raw, event_id=event_id)\n",
    "\n",
    "    event_c = np.array([e[2] for e in events[0]])\n",
    "    event_t = np.array([e[0] for e in events[0]])\n",
    "\n",
    "    count1 = 0\n",
    "    count2 = 0\n",
    "    new_events = []\n",
    "    for i, (et, ec) in enumerate(zip(event_t, event_c)):\n",
    "        if ec < 7 and ec > 1:\n",
    "            count1 += 1\n",
    "            if event_c[i+1] == 8:\n",
    "                new_events.append(np.array([event_t[i+1], 0, ec]))\n",
    "            else:\n",
    "                print('error1')\n",
    "                continue\n",
    "\n",
    "        elif ec < 16 and ec > 10:\n",
    "            count2 += 1\n",
    "            split_events = event_c[i-18:i-4]\n",
    "            #print(split_events)\n",
    "            tind = np.nonzero(split_events == 7)[0][-1]\n",
    "\n",
    "            tind += i-18\n",
    "\n",
    "            if event_c[tind+1] == 8:\n",
    "                new_events.append(np.array([event_t[tind+1], 0, ec-9]))\n",
    "            else:\n",
    "                print('erorr5')\n",
    "                print(event_c[i-20:i])\n",
    "\n",
    "\n",
    "    print(count1)\n",
    "    print(count2)\n",
    "\n",
    "    new_events = np.array(new_events)\n",
    "\n",
    "    ep = mne.Epochs(raw,\n",
    "                    new_events,\n",
    "                    event_id=epoch_event_id,\n",
    "                    tmin=0,\n",
    "                    tmax=4,\n",
    "                    baseline=None,\n",
    "                    picks=['eeg'],\n",
    "                    reject=None,\n",
    "                    preload=True)\n",
    "    epochs.append(ep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, session in enumerate(epochs):\n",
    "    sid = str(i+2)\n",
    "    outdir = base + f\"preproc1_20hz_noica/inner_speech_long/sub\" + str(i)\n",
    "    for epoch, event in zip(session, session.events):\n",
    "        data = epoch.T.astype(np.float32)\n",
    "\n",
    "        event_id = event[-1]\n",
    "        os.makedirs(f\"{outdir}/cond{event_id-2}\", exist_ok=True)\n",
    "        n_trials = int(len(os.listdir(f\"{outdir}/cond{event_id-2}\"))/2)\n",
    "        np.save(f\"{outdir}/cond{event_id-2}/trial{n_trials}.npy\", data)\n",
    "        savemat(f\"{outdir}/cond{event_id-2}/trial{n_trials}.mat\", {'X': data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2001, 53)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53, 2001)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evokeds_avg[0].get_data().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, session in enumerate(epochs):\n",
    "    sid = str(i+2)\n",
    "    outdir = base + f\"preproc1_20hz_noica/inner_speech_long_conv/sub\" + str(i)\n",
    "    evkd = abs(evokeds_avg[i].get_data().T)\n",
    "    for epoch, event in zip(session, session.events):\n",
    "        data = epoch.T.astype(np.float32)\n",
    "\n",
    "        # multiply with evoked\n",
    "        data = data * evkd\n",
    "\n",
    "        event_id = event[-1]\n",
    "        os.makedirs(f\"{outdir}/cond{event_id-2}\", exist_ok=True)\n",
    "        n_trials = int(len(os.listdir(f\"{outdir}/cond{event_id-2}\"))/2)\n",
    "        np.save(f\"{outdir}/cond{event_id-2}/trial{n_trials}.npy\", data)\n",
    "        savemat(f\"{outdir}/cond{event_id-2}/trial{n_trials}.mat\", {'X': data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "evokeds_avg = [ep.average() for ep in epochs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare evoked responses with variance across trials shown as shading based on the epochs list\n",
    "fig, ax = plt.subplots(1, 3)\n",
    "for i, epoch in enumerate(epochs[:2]):\n",
    "    epoch.plot_image(axes=ax, show=True, picks=['O2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "evokeds = {str(i): [] for i in range(10)}\n",
    "for i, ep in enumerate(epochs):\n",
    "    for j in range(len(ep)):\n",
    "        evokeds[str(i)].append(ep[j:j+1].average())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.viz.plot_compare_evokeds(evokeds, picks='eeg', ci=True, combine='gfp')\n",
    "\n",
    "# limit y axis\n",
    "plt.ylim(4, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.viz.plot_compare_evokeds(evokeds, picks=['PO7'], ci=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ep in epochs:\n",
    "    ep.info['bads'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_epochs = mne.concatenate_epochs(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create evoked dict for each condition\n",
    "evokeds = {str(i): [] for i in range(2, 7)}\n",
    "for i in range(len(all_epochs)):\n",
    "    id = all_epochs.events[i, 2]\n",
    "    evokeds[str(id)].append(all_epochs[i:i+1].average())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot evoked response (with variance shown) for each element of the epochs list\n",
    "# create a 2 x 5 subplot and iterate over evokeds to plot into appropriate axes\n",
    "%matplotlib widget\n",
    "fig, ax = plt.subplots(1, 5, figsize=(10, 5))\n",
    "for i, key in enumerate(evokeds):\n",
    "    ev = {key: evokeds[key]}\n",
    "    mne.viz.plot_compare_evokeds(ev, picks=['T7'], ci=True, axes=ax[i], show=False, ylim=dict(eeg=[-2, 2]))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evokeds['0'][i].get_data().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a dict with channel names as keys and indices as values\n",
    "ch_names = epochs[0].ch_names\n",
    "ch_dict = {ch_names[i]: i for i in range(len(ch_names))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "# plot evoked topomap of evokeds\n",
    "trials = epochs[0].get_data()\n",
    "for i in range(100):\n",
    "    plt.plot(trials[i, ch_dict['PO7'], :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot evoked response (with variance shown) for each element of the epochs list\n",
    "# create a 2 x 5 subplot and iterate over evokeds to plot into appropriate axes\n",
    "%matplotlib widget\n",
    "fig, ax = plt.subplots(2, 5, figsize=(10, 5))\n",
    "for i, key in enumerate(evokeds):\n",
    "    ev = {key: evokeds[key]}\n",
    "    row = i // 5\n",
    "    col = i % 5\n",
    "    mne.viz.plot_compare_evokeds(ev, picks=['T7'], ci=True, axes=ax[row][col], show=False, ylim=dict(eeg=[-2, 2]))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.viz.plot_compare_evokeds({'0': evokeds['0']}, picks=['F6'], ci=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot evoked response (with variance shown) for each element of the epochs list\n",
    "# create a 2 x 5 subplot and iterate over evokeds to plot into appropriate axes\n",
    "fig, ax = plt.subplots(2, 5, figsize=(10, 5))\n",
    "for i, key in enumerate(evokeds):\n",
    "    ev = {key: evokeds[key]}\n",
    "    row = i // 5\n",
    "    col = i % 5\n",
    "    mne.viz.plot_compare_evokeds(ev, picks=['PO7'], ci=True, axes=ax[row][col], show=False, ylim=dict(eeg=[-6, 6]))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot evoked response (with variance shown) for each element of the epochs list\n",
    "# create a 2 x 5 subplot and iterate over evokeds to plot into appropriate axes\n",
    "fig, ax = plt.subplots(2, 5, figsize=(10, 5))\n",
    "for i, key in enumerate(evokeds):\n",
    "    ev = {key: evokeds[key]}\n",
    "    row = i // 5\n",
    "    col = i % 5\n",
    "    mne.viz.plot_compare_evokeds(ev, picks=['C4'], ci=True, axes=ax[row][col], show=False, ylim=dict(eeg=[-2, 2]))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot evoked response (with variance shown) for each element of the epochs list\n",
    "# create a 2 x 5 subplot and iterate over evokeds to plot into appropriate axes\n",
    "fig, ax = plt.subplots(2, 5, figsize=(10, 5))\n",
    "for i, key in enumerate(evokeds):\n",
    "    ev = {key: evokeds[key]}\n",
    "    row = i // 5\n",
    "    col = i % 5\n",
    "    mne.viz.plot_compare_evokeds(ev, picks=['F8'], ci=True, axes=ax[row][col], show=False, ylim=dict(eeg=[-3, 3]))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = epochs[0].get_data()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = epochs[0].get_data()\n",
    "data = data.transpose(1, 2, 0).reshape(data.shape[1], -1)\n",
    "\n",
    "cov = np.cov(data)\n",
    "\n",
    "# standardize the data\n",
    "data = StandardScaler().fit_transform(data.T).T\n",
    "\n",
    "# compute the covariance matrix\n",
    "cov_std = np.cov(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the covariance matrix\n",
    "%matplotlib widget\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].imshow(cov)\n",
    "# modify axis to show channel names\n",
    "ax[0].set_xticks(range(0, 53, 2), epochs[0].ch_names[::2], rotation=90)\n",
    "\n",
    "ax[1].imshow(cov_std)\n",
    "# modify axis to show channel names\n",
    "ax[1].set_xticks(range(0, 53, 2), epochs[0].ch_names[::2], rotation=90)\n",
    "e=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covs = []\n",
    "all_covs = []\n",
    "labels = []\n",
    "all_full_covs = []\n",
    "class_labels = []\n",
    "for sess, ep in enumerate(epochs):\n",
    "    data = ep.get_data()\n",
    "    chn = data.shape[1]\n",
    "    trials = data.shape[0]\n",
    "\n",
    "    data = data.transpose(1, 2, 0).reshape(data.shape[1], -1)\n",
    "\n",
    "    # standardize the data\n",
    "    data = StandardScaler().fit_transform(data.T).T\n",
    "\n",
    "    data = data.reshape(chn, -1, trials)\n",
    "\n",
    "    trial_covs = []\n",
    "    for i in range(trials):\n",
    "        cov = np.cov(data[:, :, i])\n",
    "        trial_covs.append(cov)\n",
    "        all_full_covs.append(cov)\n",
    "\n",
    "        class_labels.append(ep.events[i, 2])\n",
    "    \n",
    "    labels.extend([sess] * trials)\n",
    "\n",
    "    sess_cov = np.mean(np.array(trial_covs), axis=0)\n",
    "\n",
    "    '''\n",
    "    for i in range(trials):\n",
    "        cov = np.cov(data[:, :, i]) - sess_cov\n",
    "\n",
    "        mat = np.triu(cov).reshape(-1)\n",
    "        all_covs.append(mat[mat != 0])\n",
    "    '''\n",
    "\n",
    "    covs.append(sess_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_cov = np.mean(np.array(covs), axis=0)\n",
    "\n",
    "for sess, ep in enumerate(epochs):\n",
    "    data = ep.get_data()\n",
    "    chn = data.shape[1]\n",
    "    trials = data.shape[0]\n",
    "\n",
    "    data = data.transpose(1, 2, 0).reshape(data.shape[1], -1)\n",
    "\n",
    "    # standardize the data\n",
    "    data = StandardScaler().fit_transform(data.T).T\n",
    "\n",
    "    data = data.reshape(chn, -1, trials)\n",
    "\n",
    "    d = avg_cov - covs[sess]\n",
    "\n",
    "    for i in range(trials):\n",
    "        cov = np.cov(data[:, :, i]) + d\n",
    "\n",
    "        mat = np.triu(cov).reshape(-1)\n",
    "        all_covs.append(mat[mat != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save session differences\n",
    "for sess, ep in enumerate(epochs):\n",
    "    d = avg_cov - covs[sess]\n",
    "    outdir = base + f\"/preproc1_40hz_noica/inner_speech_long/avg_cov_diff{sess}.npy\"\n",
    "\n",
    "    np.save(outdir, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save session differences\n",
    "for sess, ep in enumerate(epochs):\n",
    "    outdir = base + f\"/preproc1_40hz_noica/inner_speech_long/cov{sess}.npy\"\n",
    "\n",
    "    np.save(outdir, covs[sess])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_full_covs = np.array(all_full_covs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute mean of covariances across class_labels\n",
    "class_covs = []\n",
    "for cl in np.unique(class_labels):\n",
    "    cov = np.mean(all_full_covs[class_labels == cl], axis=0)\n",
    "    class_covs.append(cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the covariance matrix\n",
    "%matplotlib widget\n",
    "fig, ax = plt.subplots(1, 5, figsize=(10, 5))\n",
    "for i, cov in enumerate(class_covs):\n",
    "    ax[i].imshow(cov)\n",
    "    ax[i].set_xticks(range(0, 53, 2), epochs[0].ch_names[::2], rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "class_std = np.std(np.array(class_covs), axis=0)/np.mean(np.array(class_covs), axis=0)\n",
    "plt.imshow(class_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_std[class_std>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the covariance matrix\n",
    "%matplotlib widget\n",
    "fig, ax = plt.subplots(2, 5, figsize=(10, 5))\n",
    "for i, cov in enumerate(covs):\n",
    "    row = i // 5\n",
    "    col = i % 5\n",
    "    ax[row][col].imshow(cov)\n",
    "    ax[row][col].set_xticks(range(0, 53, 2), epochs[0].ch_names[::2], rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute riemannian distance between each session using covs\n",
    "riemann_dist = []\n",
    "for i in range(len(covs)):\n",
    "    dist = []\n",
    "    for j in range(len(covs)):\n",
    "        dist.append(distance_riemann(covs[i], covs[j]))\n",
    "\n",
    "    riemann_dist.append(np.array(dist))\n",
    "\n",
    "riemann_dist = np.array(riemann_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(riemann_dist, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "plt.imshow(riemann_dist)\n",
    "\n",
    "# add colorbar\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_cov = np.mean(np.array(covs), axis=0)\n",
    "\n",
    "# replace each row and column iteratively of each session with avg_cov and compute riemannian distance\n",
    "riemann_dist = []\n",
    "for i in range(len(covs)):\n",
    "    \n",
    "    dist = []\n",
    "    for j in range(covs[i].shape[0]):\n",
    "        cov = covs[i].copy()\n",
    "        avg_cov_copy = avg_cov.copy()\n",
    "        cov = np.delete(cov, j, axis=0)\n",
    "        cov = np.delete(cov, j, axis=1)\n",
    "\n",
    "        avg_cov_copy = np.delete(avg_cov_copy, j, axis=0)\n",
    "        avg_cov_copy = np.delete(avg_cov_copy, j, axis=1)\n",
    "\n",
    "        d = distance_riemann(cov, avg_cov_copy)\n",
    "        dist.append(d)\n",
    "\n",
    "    riemann_dist.append(np.array(dist))\n",
    "\n",
    "riemann_dist = np.mean(np.array(riemann_dist), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot scores as topomap\n",
    "%matplotlib widget\n",
    "mne.viz.plot_topomap(riemann_dist, epochs[0].info, vmin=5, show_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, ch in enumerate(epochs[0].info['ch_names']):\n",
    "    if riemann_dist[i] < 5.3:\n",
    "        print(i, ch, riemann_dist[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist\n",
    "for i in range(len(covs)):\n",
    "    cov = covs[i].copy()\n",
    "    avg_cov_copy = avg_cov.copy()\n",
    "    cov = np.delete(cov, [1, 5, 6, 7, 9, 17, 42, 50], axis=0)\n",
    "    cov = np.delete(cov, [1, 5, 6, 7, 9, 17, 42, 50], axis=1)\n",
    "\n",
    "    avg_cov_copy = np.delete(avg_cov_copy, [1, 5, 6, 7, 9, 17, 42, 50], axis=0)\n",
    "    avg_cov_copy = np.delete(avg_cov_copy, [1, 5, 6, 7, 9, 17, 42, 50], axis=1)\n",
    "\n",
    "    d = distance_riemann(cov, avg_cov_copy)\n",
    "    dist.append(d)\n",
    "\n",
    "np.mean(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(sess_riemann_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster all_covs with KMeans\n",
    "kmeans = KMeans(n_clusters=6).fit(np.array(all_covs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed = kmeans.transform(np.array(all_covs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the transformed data\n",
    "tsne_data = TSNE(n_components=2).fit_transform(np.array(all_covs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_data = PCA(n_components=10).fit_transform(np.array(all_covs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(labels)\n",
    "class_labels = np.array(class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tsne(tsne_data, labels, ax):\n",
    "    # Get the unique labels\n",
    "    unique_labels = np.unique(labels)\n",
    "\n",
    "    # Plot each cluster with a different color or marker\n",
    "    for label in unique_labels:\n",
    "        mask = labels == label\n",
    "        ax.scatter(tsne_data[mask, 0], tsne_data[mask, 1], label=label, alpha=0.3, s=5)\n",
    "\n",
    "    # Add a legend\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure and axis\n",
    "%matplotlib widget\n",
    "fig, ax = plt.subplots(1, 3, figsize=(10, 5))\n",
    "plot_tsne(tsne_data, labels, ax[0])\n",
    "plot_tsne(tsne_data, kmeans.labels_, ax[1])\n",
    "plot_tsne(tsne_data, class_labels, ax[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure and axis\n",
    "comps = [0, 1]\n",
    "fig, ax = plt.subplots(1, 3, figsize=(10, 5))\n",
    "plot_tsne(pca_data[:, comps], labels, ax[0])\n",
    "plot_tsne(pca_data[:, comps], kmeans.labels_, ax[1])\n",
    "plot_tsne(pca_data[:, comps], class_labels, ax[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def session_lda(chid):\n",
    "    labels = []\n",
    "    data = []\n",
    "    for i, ep in enumerate(epochs):\n",
    "        epoch = ep.get_data()[:, chid, 1000:]\n",
    "        labels.extend([i] * epoch.shape[0])\n",
    "        data.append(epoch[: , ::10]*1e6)\n",
    "\n",
    "    data = np.concatenate(np.array(data), axis=0)\n",
    "\n",
    "    # train LDA model\n",
    "    lda = LDA()\n",
    "    lda.fit(data, labels)\n",
    "\n",
    "    # get accuracy\n",
    "    return lda.score(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "for i in range(len(epochs[0].ch_names)):\n",
    "    scores[epochs[0].ch_names[i]] = session_lda(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot scores as topomap\n",
    "%matplotlib widget\n",
    "mne.viz.plot_topomap(np.array(list(scores.values())), epochs[0].info, vmin=0.1, show_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ch in epochs[0].info['ch_names']:\n",
    "    if scores[ch] > 0.2:\n",
    "        print(ch, scores[ch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raws[0].plot_sensors(ch_type='eeg', kind='topomap', show_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(scores.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick eeg channels\n",
    "raws[0].get_data().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load spatial PFI\n",
    "path = os.path.join('..', 'results', 'disp_epoched', 'eeg', '9sessions_noica', 'standard_cov_longepochs',\n",
    "                    'val_loss_PFIeeg_closest1.npy')\n",
    "pfi_ch1 = np.load(open(path, 'rb'))\n",
    "pfi_ch1 = np.mean(pfi_ch1, axis=0)\n",
    "pfi_ch1 = pfi_ch1[0, 0] - pfi_ch1[:, 1:]\n",
    "\n",
    "evoked_ch1 = mne.EvokedArray(pfi_ch1.T, raws[0].info, tmin=0)\n",
    "\n",
    "%matplotlib widget\n",
    "evoked_ch1.plot_topomap(times=[0], ch_type='eeg', time_unit='ms', scalings=1, units='Gradient magnitude', time_format='', vmin=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find indices of channels in pfi_ch1 that are higher than 0.1\n",
    "chid = []\n",
    "for i, ch in enumerate(raws[0].info['ch_names']):\n",
    "    if pfi_ch1[0, i] > 0.1:\n",
    "        chid.append(i)\n",
    "        print(ch)\n",
    "\n",
    "print(chid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('main')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "84a3ebe666650a68380744730c1b34178a4e2d05dc952cdf65b44a0ef828689f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
