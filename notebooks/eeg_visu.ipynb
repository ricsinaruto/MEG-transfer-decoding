{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import mne\n",
    "import osl\n",
    "import yaml\n",
    "import pickle\n",
    "from scipy.io import savemat\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "# import distance_riemann\n",
    "from pyriemann.utils.distance import distance_riemann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# closest 1 for eeg data\n",
    "a = np.arange(53).reshape(-1, 1)\n",
    "pickle.dump(a, open('eeg_closest1', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(epochs[0].ch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = ['TP9', 'TP7', 'CP3', 'CP1', 'P1', 'P3', 'P5', 'P7', 'T7', 'T9', 'TP10', 'TP8', 'CP4', 'CP2', 'P2', 'P4', 'P6', 'P8', 'T8', 'T10', 'FT7', 'FT8']\n",
    "\n",
    "# print indices of channels not to remove\n",
    "print([i for i, ch in enumerate(epochs[0].info['ch_names']) if ch in keep])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rem = ['F7', 'F2', 'F4', 'F6', 'FT9', 'T9', 'P4', 'OZ',\n",
    "        'F3', 'P1', 'PO7', 'PO3', 'PO4', 'PO8', 'O1', 'O2']\n",
    "\n",
    "# print indices of channels not to remove\n",
    "for i, ch in enumerate(epochs[0].info['ch_names']):\n",
    "    if ch not in rem:\n",
    "        print(i, ch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file ../scripts/rich_data/eeg/session2/preproc1_20hz_noica/oslpy/preproc/preproc_preproc_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 0 ... 3068699 =      0.000 ...  3068.699 secs\n",
      "Ready.\n",
      "Reading 0 ... 3068699  =      0.000 ...  3068.699 secs...\n",
      "Opening raw data file ../scripts/rich_data/eeg/session3/preproc1_20hz_noica/oslpy/preproc/preproc_preproc_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 0 ... 2754699 =      0.000 ...  2754.699 secs\n",
      "Ready.\n",
      "Reading 0 ... 2754699  =      0.000 ...  2754.699 secs...\n",
      "Opening raw data file ../scripts/rich_data/eeg/session4/preproc1_20hz_noica/oslpy/preproc/preproc_preproc_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 0 ... 2758099 =      0.000 ...  2758.099 secs\n",
      "Ready.\n",
      "Reading 0 ... 2758099  =      0.000 ...  2758.099 secs...\n",
      "Opening raw data file ../scripts/rich_data/eeg/session5/preproc1_20hz_noica/oslpy/preproc/preproc_preproc_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 0 ... 2786699 =      0.000 ...  2786.699 secs\n",
      "Ready.\n",
      "Reading 0 ... 2786699  =      0.000 ...  2786.699 secs...\n",
      "Opening raw data file ../scripts/rich_data/eeg/session6/preproc1_20hz_noica/oslpy/preproc/preproc_preproc_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 0 ... 2769299 =      0.000 ...  2769.299 secs\n",
      "Ready.\n",
      "Reading 0 ... 2769299  =      0.000 ...  2769.299 secs...\n",
      "Opening raw data file ../scripts/rich_data/eeg/session7/preproc1_20hz_noica/oslpy/preproc/preproc_preproc_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 0 ... 2738499 =      0.000 ...  2738.499 secs\n",
      "Ready.\n",
      "Reading 0 ... 2738499  =      0.000 ...  2738.499 secs...\n",
      "Opening raw data file ../scripts/rich_data/eeg/session8/preproc1_20hz_noica/oslpy/preproc/preproc_preproc_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 0 ... 3208899 =      0.000 ...  3208.899 secs\n",
      "Ready.\n",
      "Reading 0 ... 3208899  =      0.000 ...  3208.899 secs...\n",
      "Opening raw data file ../scripts/rich_data/eeg/session9/preproc1_20hz_noica/oslpy/preproc/preproc_preproc_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 0 ... 2829399 =      0.000 ...  2829.399 secs\n",
      "Ready.\n",
      "Reading 0 ... 2829399  =      0.000 ...  2829.399 secs...\n",
      "Opening raw data file ../scripts/rich_data/eeg/session10/preproc1_20hz_noica/oslpy/preproc/preproc_preproc_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 0 ... 2866899 =      0.000 ...  2866.899 secs\n",
      "Ready.\n",
      "Reading 0 ... 2866899  =      0.000 ...  2866.899 secs...\n",
      "Opening raw data file ../scripts/rich_data/eeg/session11/preproc1_20hz_noica/oslpy/preproc/preproc_preproc_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 0 ... 2789799 =      0.000 ...  2789.799 secs\n",
      "Ready.\n",
      "Reading 0 ... 2789799  =      0.000 ...  2789.799 secs...\n"
     ]
    }
   ],
   "source": [
    "raws = []\n",
    "\n",
    "for i in range(2, 12):\n",
    "    sid = str(i)\n",
    "    fif_name = \"preproc_preproc_raw.fif\"\n",
    "    base = \"../scripts/rich_data/eeg/\"\n",
    "    dataset_path = base + f\"session{sid}/preproc1_20hz_noica/oslpy/preproc/\" + fif_name\n",
    "\n",
    "    # load raw data\n",
    "    raws.append(mne.io.read_raw_fif(dataset_path, preload=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'AF4': 10, 'AF8': 10, 'AFZ': 9, 'AF3': 7, 'FP1': 6, 'AF7': 4, 'FP2': 3, 'Fz': 3, 'FT10': 2, 'FPZ': 1, 'F8': 1, 'FT7': 1, 'O1': 1, 'OZ': 1, 'FT9': 1})\n"
     ]
    }
   ],
   "source": [
    "bads = Counter()\n",
    "for raw in raws:\n",
    "    bads.update(raw.info['bads'])\n",
    "print(bads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FP1', 'FP2', 'AF3', 'AFZ', 'AF4', 'AF8', 'Fz', 'AF7', 'FT10']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_channels = [ch for ch, count in bads.items() if count > 1]\n",
    "bad_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raws = [raw.drop_channels(bad_channels) for raw in raws]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save raws\n",
    "for i in range(2, 12):\n",
    "    sid = str(i)\n",
    "    fif_name = \"preproc_preproc_raw.fif\"\n",
    "    base = \"/gpfs2/well/woolrich/projects/disp_csaky/eeg/\"\n",
    "    dataset_path = base + f\"session{sid}/preproc1_40hz_noica/oslpy/\" + fif_name\n",
    "\n",
    "    # save raw data\n",
    "    raws[i-2].save(dataset_path, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raws[0].plot_sensors(ch_type='eeg', kind='topomap', show_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "raws[0].plot(n_channels=30, duration=50)\n",
    "e=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['11', '12', '13', '14', '15', '2', '3', '4', '5', '6', '7', '8']\n",
      "176\n",
      "162\n",
      "Not setting metadata\n",
      "1352 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1352 events and 1001 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nv/wjmf18wd5_j38vg9v0cthl5h0000gn/T/ipykernel_2470/1653781664.py:69: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  ep = mne.Epochs(raw,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 bad epochs dropped\n",
      "Used Annotations descriptions: ['11', '12', '13', '14', '15', '2', '3', '4', '5', '6', '7', '8']\n",
      "error1\n",
      "178\n",
      "162\n",
      "Not setting metadata\n",
      "1356 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1356 events and 1001 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nv/wjmf18wd5_j38vg9v0cthl5h0000gn/T/ipykernel_2470/1653781664.py:69: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  ep = mne.Epochs(raw,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 bad epochs dropped\n",
      "Used Annotations descriptions: ['11', '12', '13', '14', '15', '2', '3', '4', '5', '6', '7', '8']\n",
      "179\n",
      "162\n",
      "Not setting metadata\n",
      "1364 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1364 events and 1001 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nv/wjmf18wd5_j38vg9v0cthl5h0000gn/T/ipykernel_2470/1653781664.py:69: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  ep = mne.Epochs(raw,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 bad epochs dropped\n",
      "Used Annotations descriptions: ['10', '11', '12', '13', '14', '15', '2', '3', '4', '5', '6', '7', '8']\n",
      "182\n",
      "160\n",
      "Not setting metadata\n",
      "1368 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1368 events and 1001 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nv/wjmf18wd5_j38vg9v0cthl5h0000gn/T/ipykernel_2470/1653781664.py:69: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  ep = mne.Epochs(raw,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 bad epochs dropped\n",
      "Used Annotations descriptions: ['10', '11', '12', '13', '14', '15', '2', '3', '4', '5', '6', '7', '8']\n",
      "177\n",
      "161\n",
      "Not setting metadata\n",
      "1352 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1352 events and 1001 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nv/wjmf18wd5_j38vg9v0cthl5h0000gn/T/ipykernel_2470/1653781664.py:69: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  ep = mne.Epochs(raw,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 bad epochs dropped\n",
      "Used Annotations descriptions: ['10', '11', '12', '13', '14', '15', '2', '3', '4', '5', '6', '7', '8']\n",
      "183\n",
      "160\n",
      "Not setting metadata\n",
      "1372 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1372 events and 1001 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nv/wjmf18wd5_j38vg9v0cthl5h0000gn/T/ipykernel_2470/1653781664.py:69: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  ep = mne.Epochs(raw,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 bad epochs dropped\n",
      "Used Annotations descriptions: ['11', '12', '13', '14', '15', '2', '3', '4', '5', '6', '7', '8']\n",
      "183\n",
      "162\n",
      "Not setting metadata\n",
      "1380 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1380 events and 1001 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nv/wjmf18wd5_j38vg9v0cthl5h0000gn/T/ipykernel_2470/1653781664.py:69: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  ep = mne.Epochs(raw,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 bad epochs dropped\n",
      "Used Annotations descriptions: ['11', '12', '13', '14', '15', '2', '3', '4', '5', '6', '7', '8']\n",
      "189\n",
      "162\n",
      "Not setting metadata\n",
      "1404 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1404 events and 1001 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nv/wjmf18wd5_j38vg9v0cthl5h0000gn/T/ipykernel_2470/1653781664.py:69: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  ep = mne.Epochs(raw,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 bad epochs dropped\n",
      "Used Annotations descriptions: ['11', '12', '13', '14', '15', '2', '3', '4', '5', '6', '7', '8']\n",
      "177\n",
      "162\n",
      "Not setting metadata\n",
      "1356 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1356 events and 1001 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nv/wjmf18wd5_j38vg9v0cthl5h0000gn/T/ipykernel_2470/1653781664.py:69: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  ep = mne.Epochs(raw,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 bad epochs dropped\n",
      "Used Annotations descriptions: ['10', '11', '12', '13', '14', '15', '2', '3', '4', '5', '6', '7', '8']\n",
      "188\n",
      "161\n",
      "Not setting metadata\n",
      "1396 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1396 events and 1001 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nv/wjmf18wd5_j38vg9v0cthl5h0000gn/T/ipykernel_2470/1653781664.py:69: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  ep = mne.Epochs(raw,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "# find epochs specific to words\n",
    "event_id = {'2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '10': 10, '11': 11, '12': 12, '13': 13, '14': 14, '15': 15}\n",
    "epoch_event_id = {'words/hungry': 2, 'words/thirst': 3, 'words/tired': 4, 'words/toilet': 5, 'words/pain': 6}\n",
    "\n",
    "epochs = []\n",
    "for raw in raws:\n",
    "    events = mne.events_from_annotations(raw, event_id=event_id)\n",
    "\n",
    "    event_c = np.array([e[2] for e in events[0]])\n",
    "    event_t = np.array([e[0] for e in events[0]])\n",
    "\n",
    "    count1 = 0\n",
    "    count2 = 0\n",
    "    new_events = []\n",
    "    for i, (et, ec) in enumerate(zip(event_t, event_c)):\n",
    "        if ec < 7 and ec > 1:\n",
    "            count1 += 1\n",
    "            if event_c[i+1] == 8:\n",
    "                new_events.append(np.array([event_t[i+1], 0, ec]))\n",
    "            else:\n",
    "                print('error1')\n",
    "                continue\n",
    "            if event_c[i+2] == 8:\n",
    "                new_events.append(np.array([event_t[i+2], 0, ec]))\n",
    "            else:\n",
    "                print('error2')\n",
    "            if event_c[i+3] == 8:\n",
    "                new_events.append(np.array([event_t[i+3], 0, ec]))\n",
    "            else:\n",
    "                print('error3')\n",
    "            if event_c[i+4] == 8:\n",
    "                new_events.append(np.array([event_t[i+4], 0, ec]))\n",
    "            else:\n",
    "                print('error4')\n",
    "\n",
    "        elif ec < 16 and ec > 10:\n",
    "            count2 += 1\n",
    "            split_events = event_c[i-18:i-4]\n",
    "            #print(split_events)\n",
    "            tind = np.nonzero(split_events == 7)[0][-1]\n",
    "\n",
    "            tind += i-18\n",
    "\n",
    "            if event_c[tind+1] == 8:\n",
    "                new_events.append(np.array([event_t[tind+1], 0, ec-9]))\n",
    "            else:\n",
    "                print('erorr5')\n",
    "                print(event_c[i-20:i])\n",
    "            if event_c[tind+2] == 8:\n",
    "                new_events.append(np.array([event_t[tind+2], 0, ec-9]))\n",
    "            else:\n",
    "                print('erorr6')\n",
    "                print(event_c[i-20:i])\n",
    "            if event_c[tind+3] == 8:\n",
    "                new_events.append(np.array([event_t[tind+3], 0, ec-9]))\n",
    "            else:\n",
    "                print('erorr7')\n",
    "            if event_c[tind+4] == 8:\n",
    "                new_events.append(np.array([event_t[tind+4], 0, ec-9]))\n",
    "            else:\n",
    "                print('erorr8')\n",
    "\n",
    "\n",
    "    print(count1)\n",
    "    print(count2)\n",
    "\n",
    "    new_events = np.array(new_events)\n",
    "\n",
    "    ep = mne.Epochs(raw,\n",
    "                    new_events,\n",
    "                    event_id=epoch_event_id,\n",
    "                    tmin=0,\n",
    "                    tmax=1,\n",
    "                    baseline=None,\n",
    "                    picks=['eeg'],\n",
    "                    reject=None,\n",
    "                    preload=True)\n",
    "    epochs.append(ep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['11', '12', '13', '14', '15', '2', '3', '4', '5', '6', '7', '8']\n",
      "176\n",
      "162\n",
      "Not setting metadata\n",
      "338 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 338 events and 4001 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nv/wjmf18wd5_j38vg9v0cthl5h0000gn/T/ipykernel_2470/1012683308.py:44: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  ep = mne.Epochs(raw,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 bad epochs dropped\n",
      "Used Annotations descriptions: ['11', '12', '13', '14', '15', '2', '3', '4', '5', '6', '7', '8']\n",
      "error1\n",
      "178\n",
      "162\n",
      "Not setting metadata\n",
      "339 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 339 events and 4001 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nv/wjmf18wd5_j38vg9v0cthl5h0000gn/T/ipykernel_2470/1012683308.py:44: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  ep = mne.Epochs(raw,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 bad epochs dropped\n",
      "Used Annotations descriptions: ['11', '12', '13', '14', '15', '2', '3', '4', '5', '6', '7', '8']\n",
      "179\n",
      "162\n",
      "Not setting metadata\n",
      "341 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 341 events and 4001 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nv/wjmf18wd5_j38vg9v0cthl5h0000gn/T/ipykernel_2470/1012683308.py:44: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  ep = mne.Epochs(raw,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 bad epochs dropped\n",
      "Used Annotations descriptions: ['10', '11', '12', '13', '14', '15', '2', '3', '4', '5', '6', '7', '8']\n",
      "182\n",
      "160\n",
      "Not setting metadata\n",
      "342 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 342 events and 4001 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nv/wjmf18wd5_j38vg9v0cthl5h0000gn/T/ipykernel_2470/1012683308.py:44: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  ep = mne.Epochs(raw,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 bad epochs dropped\n",
      "Used Annotations descriptions: ['10', '11', '12', '13', '14', '15', '2', '3', '4', '5', '6', '7', '8']\n",
      "177\n",
      "161\n",
      "Not setting metadata\n",
      "338 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 338 events and 4001 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nv/wjmf18wd5_j38vg9v0cthl5h0000gn/T/ipykernel_2470/1012683308.py:44: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  ep = mne.Epochs(raw,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 bad epochs dropped\n",
      "Used Annotations descriptions: ['10', '11', '12', '13', '14', '15', '2', '3', '4', '5', '6', '7', '8']\n",
      "183\n",
      "160\n",
      "Not setting metadata\n",
      "343 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 343 events and 4001 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nv/wjmf18wd5_j38vg9v0cthl5h0000gn/T/ipykernel_2470/1012683308.py:44: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  ep = mne.Epochs(raw,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 bad epochs dropped\n",
      "Used Annotations descriptions: ['11', '12', '13', '14', '15', '2', '3', '4', '5', '6', '7', '8']\n",
      "183\n",
      "162\n",
      "Not setting metadata\n",
      "345 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 345 events and 4001 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nv/wjmf18wd5_j38vg9v0cthl5h0000gn/T/ipykernel_2470/1012683308.py:44: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  ep = mne.Epochs(raw,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 bad epochs dropped\n",
      "Used Annotations descriptions: ['11', '12', '13', '14', '15', '2', '3', '4', '5', '6', '7', '8']\n",
      "189\n",
      "162\n",
      "Not setting metadata\n",
      "351 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 351 events and 4001 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nv/wjmf18wd5_j38vg9v0cthl5h0000gn/T/ipykernel_2470/1012683308.py:44: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  ep = mne.Epochs(raw,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 bad epochs dropped\n",
      "Used Annotations descriptions: ['11', '12', '13', '14', '15', '2', '3', '4', '5', '6', '7', '8']\n",
      "177\n",
      "162\n",
      "Not setting metadata\n",
      "339 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 339 events and 4001 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nv/wjmf18wd5_j38vg9v0cthl5h0000gn/T/ipykernel_2470/1012683308.py:44: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  ep = mne.Epochs(raw,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 bad epochs dropped\n",
      "Used Annotations descriptions: ['10', '11', '12', '13', '14', '15', '2', '3', '4', '5', '6', '7', '8']\n",
      "188\n",
      "161\n",
      "Not setting metadata\n",
      "349 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 349 events and 4001 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nv/wjmf18wd5_j38vg9v0cthl5h0000gn/T/ipykernel_2470/1012683308.py:44: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  ep = mne.Epochs(raw,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "# find epochs specific to words\n",
    "event_id = {'2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '10': 10, '11': 11, '12': 12, '13': 13, '14': 14, '15': 15}\n",
    "epoch_event_id = {'words/hungry': 2, 'words/thirst': 3, 'words/tired': 4, 'words/toilet': 5, 'words/pain': 6}\n",
    "\n",
    "epochs = []\n",
    "for raw in raws:\n",
    "    events = mne.events_from_annotations(raw, event_id=event_id)\n",
    "\n",
    "    event_c = np.array([e[2] for e in events[0]])\n",
    "    event_t = np.array([e[0] for e in events[0]])\n",
    "\n",
    "    count1 = 0\n",
    "    count2 = 0\n",
    "    new_events = []\n",
    "    for i, (et, ec) in enumerate(zip(event_t, event_c)):\n",
    "        if ec < 7 and ec > 1:\n",
    "            count1 += 1\n",
    "            if event_c[i+1] == 8:\n",
    "                new_events.append(np.array([event_t[i+1], 0, ec]))\n",
    "            else:\n",
    "                print('error1')\n",
    "                continue\n",
    "\n",
    "        elif ec < 16 and ec > 10:\n",
    "            count2 += 1\n",
    "            split_events = event_c[i-18:i-4]\n",
    "            #print(split_events)\n",
    "            tind = np.nonzero(split_events == 7)[0][-1]\n",
    "\n",
    "            tind += i-18\n",
    "\n",
    "            if event_c[tind+1] == 8:\n",
    "                new_events.append(np.array([event_t[tind+1], 0, ec-9]))\n",
    "            else:\n",
    "                print('erorr5')\n",
    "                print(event_c[i-20:i])\n",
    "\n",
    "\n",
    "    print(count1)\n",
    "    print(count2)\n",
    "\n",
    "    new_events = np.array(new_events)\n",
    "\n",
    "    ep = mne.Epochs(raw,\n",
    "                    new_events,\n",
    "                    event_id=epoch_event_id,\n",
    "                    tmin=0,\n",
    "                    tmax=4,\n",
    "                    baseline=None,\n",
    "                    picks=['eeg'],\n",
    "                    reject=None,\n",
    "                    preload=True)\n",
    "    epochs.append(ep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, session in enumerate(epochs):\n",
    "    sid = str(i+2)\n",
    "    outdir = base + f\"session{sid}/preproc1_40hz_noica/inner_speech_long/sub\" + str(i)\n",
    "    for epoch, event in zip(session, session.events):\n",
    "        data = epoch.T.astype(np.float32)\n",
    "\n",
    "        event_id = event[-1]\n",
    "        os.makedirs(f\"{outdir}/cond{event_id-2}\", exist_ok=True)\n",
    "        n_trials = int(len(os.listdir(f\"{outdir}/cond{event_id-2}\"))/2)\n",
    "        np.save(f\"{outdir}/cond{event_id-2}/trial{n_trials}.npy\", data)\n",
    "        savemat(f\"{outdir}/cond{event_id-2}/trial{n_trials}.mat\", {'X': data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "evokeds_avg = [ep.average() for ep in epochs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "285acd5724be4751b5b9ac5567067f14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fad43c43df0>]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct a sinusoidal wave with a frequency of 10 Hz at 1000 Hz sampling rate\n",
    "sfreq = 1000\n",
    "times = np.arange(sfreq) / sfreq\n",
    "sin = np.sin(2 * np.pi * 10 * times)\n",
    "\n",
    "evkd_chn = evkd[46][500:1500]\n",
    "\n",
    "convolved = np.convolve(sin, evkd_chn, mode='same')\n",
    "convolved = np.convolve(convolved, evkd_chn, mode='same')\n",
    "\n",
    "%matplotlib widget\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.plot(sin*evkd_chn)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(evkd_chn, color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = epochs[0].get_data()\n",
    "evkd = np.mean(trials, axis=0)\n",
    "\n",
    "print(trials.shape)\n",
    "print(evkd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolve each trial with evoked response\n",
    "convolved = np.zeros_like(trials)\n",
    "for ind in range(trials.shape[0]):\n",
    "    for ch in range(trials.shape[1]):\n",
    "        #convolved[ind, ch] = np.convolve(trials[ind][ch], evkd[ch], mode='same')\n",
    "        convolved[ind, ch] = trials[ind][ch]*abs(evkd[ch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8f9dd8bb70b4eefb743071cbc4bbebb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5910feb506e14bcc966ff694f339da26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9d804ef250>]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = 256\n",
    "chn = ch_dict['PO7']\n",
    "\n",
    "%matplotlib widget\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.plot(trials[ind, chn])\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(convolved[ind, chn], color='r')\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.plot(evkd[chn])\n",
    "\n",
    "convolved_evkd = np.mean(convolved, axis=0)\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(convolved_evkd[chn], color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare evoked responses with variance across trials shown as shading based on the epochs list\n",
    "fig, ax = plt.subplots(1, 3)\n",
    "for i, epoch in enumerate(epochs[:2]):\n",
    "    epoch.plot_image(axes=ax, show=True, picks=['O2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evokeds = {str(i): [] for i in range(10)}\n",
    "for i, ep in enumerate(epochs):\n",
    "    for j in range(len(ep)):\n",
    "        evokeds[str(i)].append(ep[j:j+1].average())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.viz.plot_compare_evokeds(evokeds, picks='eeg', ci=True, combine='gfp')\n",
    "\n",
    "# limit y axis\n",
    "plt.ylim(4, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.viz.plot_compare_evokeds(evokeds, picks=['PO7'], ci=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nv/wjmf18wd5_j38vg9v0cthl5h0000gn/T/ipykernel_2470/1065167818.py:4: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  all_epochs = mne.concatenate_epochs(epochs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "3192 matching events found\n",
      "No baseline correction applied\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nv/wjmf18wd5_j38vg9v0cthl5h0000gn/T/ipykernel_2470/1065167818.py:4: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  all_epochs = mne.concatenate_epochs(epochs)\n"
     ]
    }
   ],
   "source": [
    "for ep in epochs:\n",
    "    ep.info['bads'] = []\n",
    "\n",
    "all_epochs = mne.concatenate_epochs(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create evoked dict for each condition\n",
    "evokeds = {str(i): [] for i in range(2, 7)}\n",
    "for i in range(len(all_epochs)):\n",
    "    id = all_epochs.events[i, 2]\n",
    "    evokeds[str(id)].append(all_epochs[i:i+1].average())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot evoked response (with variance shown) for each element of the epochs list\n",
    "# create a 2 x 5 subplot and iterate over evokeds to plot into appropriate axes\n",
    "%matplotlib widget\n",
    "fig, ax = plt.subplots(5, 1, figsize=(10, 3))\n",
    "for i, key in enumerate(evokeds):\n",
    "    ev = {key: evokeds[key]}\n",
    "    mne.viz.plot_compare_evokeds(ev, picks=['T7'], ci=True, axes=ax[i], show=False, ylim=dict(eeg=[-2, 2]))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.viz.plot_compare_evokeds(evokeds, picks=['OZ'], ci=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dae55ea119b946e7b09158c99d44faa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "529a3ca07be64ec18be9254081c3008a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56e44fd16f0841288e5f86ba323a522b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e325221a77bb4938b183074fe0fb1268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ad375e1a6494e6d9baf7e35a5309520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4eede17652940e586a04dec9be68956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<Figure size 800x600 with 2 Axes>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "mne.viz.plot_compare_evokeds(evokeds, picks=['F2'], ci=False)\n",
    "mne.viz.plot_compare_evokeds(evokeds, picks=['OZ'], ci=False)\n",
    "mne.viz.plot_compare_evokeds(evokeds, picks=['P3'], ci=False)\n",
    "mne.viz.plot_compare_evokeds(evokeds, picks=['T9'], ci=False)\n",
    "mne.viz.plot_compare_evokeds(evokeds, picks=['FT8'], ci=False)\n",
    "mne.viz.plot_compare_evokeds(evokeds, picks=['C2'], ci=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "evkd0 = epochs[0].average()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot evoked response for each channel over the scalp\n",
    "evkd0.plot_topo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a dict with channel names as keys and indices as values\n",
    "ch_names = epochs[0].ch_names\n",
    "ch_dict = {ch_names[i]: i for i in range(len(ch_names))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "mne.viz.plot_compare_evokeds({'0': evokeds['0']}, picks=['T9'], ci=True)\n",
    "mne.viz.plot_compare_evokeds({'0': evokeds['1']}, picks=['T9'], ci=True)\n",
    "mne.viz.plot_compare_evokeds({'0': evokeds['2']}, picks=['T9'], ci=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5c0ee6af6bf4cf9b091099533938110",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9d67f27b80>]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "plt.plot(trials[100, ch_dict['OZ'], :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute pca over time x trials\n",
    "pca = PCA(n_components=10)\n",
    "\n",
    "# fit pca to data\n",
    "data = trials[:, ch_dict['T9'], :]\n",
    "pca.fit(data)\n",
    "\n",
    "# get the principal components\n",
    "comps = pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_dict['T9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fed86232ccb347deb547e290ae92f46e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7facf7fba970>]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "plt.plot(comps[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b1c2dd990fc4d298183f8c1b38d9e68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fad97583fd0>]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "ind = 129\n",
    "\n",
    "# fit model to data\n",
    "pca_comp0 = np.repeat(comps[0].reshape(1, -1), data.shape[0], axis=0)\n",
    "data0 = np.array([np.roll(data[ind], i) for i in range(-50,50)]).T\n",
    "model.fit(data0, comps[0].T)\n",
    "\n",
    "# denoise data\n",
    "denoised = model.predict(data0)\n",
    "\n",
    "%matplotlib widget\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.plot(data[ind])\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(denoised.reshape(-1), color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolled_ev = np.mean(rolled, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.plot(rolled_ev[ch_dict['T9'], :])\n",
    "\n",
    "# make second axis\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(evkd[ch_dict['T9'], 50:], color='orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each trial in trials find the index of the maximum value within the time window\n",
    "time_window = [350, 450]\n",
    "max_inds = np.argmax(trials[:, ch_dict['T9'], time_window[0]:time_window[1]], axis=1)\n",
    "max_inds += time_window[0]\n",
    "\n",
    "peak = 400\n",
    "# realign the last dimension of each trial so that max_inds becomes the peak\n",
    "rolled = []\n",
    "for i in range(trials.shape[0]):\n",
    "    trial = np.roll(trials[i], peak - max_inds[i], axis=1)\n",
    "    rolled.append(trial[:, 50:950])\n",
    "\n",
    "rolled = np.array(rolled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_dict['T9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "# plot evoked topomap of evokeds\n",
    "for i in range(1000):\n",
    "    plt.plot(rolled[i, ch_dict['T9'], :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot evoked response (with variance shown) for each element of the epochs list\n",
    "# create a 2 x 5 subplot and iterate over evokeds to plot into appropriate axes\n",
    "%matplotlib widget\n",
    "fig, ax = plt.subplots(2, 5, figsize=(10, 5))\n",
    "for i, key in enumerate(evokeds):\n",
    "    ev = {key: evokeds[key]}\n",
    "    row = i // 5\n",
    "    col = i % 5\n",
    "    mne.viz.plot_compare_evokeds(ev, picks=['T9'], ci=True, axes=ax[row][col], show=False, ylim=dict(eeg=[-2, 2]))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.viz.plot_compare_evokeds({'0': evokeds['0']}, picks=['F6'], ci=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot evoked response (with variance shown) for each element of the epochs list\n",
    "# create a 2 x 5 subplot and iterate over evokeds to plot into appropriate axes\n",
    "fig, ax = plt.subplots(2, 5, figsize=(10, 5))\n",
    "for i, key in enumerate(evokeds):\n",
    "    ev = {key: evokeds[key]}\n",
    "    row = i // 5\n",
    "    col = i % 5\n",
    "    mne.viz.plot_compare_evokeds(ev, picks=['PO7'], ci=True, axes=ax[row][col], show=False, ylim=dict(eeg=[-6, 6]))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot evoked response (with variance shown) for each element of the epochs list\n",
    "# create a 2 x 5 subplot and iterate over evokeds to plot into appropriate axes\n",
    "fig, ax = plt.subplots(2, 5, figsize=(10, 5))\n",
    "for i, key in enumerate(evokeds):\n",
    "    ev = {key: evokeds[key]}\n",
    "    row = i // 5\n",
    "    col = i % 5\n",
    "    mne.viz.plot_compare_evokeds(ev, picks=['C4'], ci=True, axes=ax[row][col], show=False, ylim=dict(eeg=[-2, 2]))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot evoked response (with variance shown) for each element of the epochs list\n",
    "# create a 2 x 5 subplot and iterate over evokeds to plot into appropriate axes\n",
    "fig, ax = plt.subplots(2, 5, figsize=(10, 5))\n",
    "for i, key in enumerate(evokeds):\n",
    "    ev = {key: evokeds[key]}\n",
    "    row = i // 5\n",
    "    col = i % 5\n",
    "    mne.viz.plot_compare_evokeds(ev, picks=['F8'], ci=True, axes=ax[row][col], show=False, ylim=dict(eeg=[-3, 3]))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1339, 53, 1001)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = epochs[0].get_data()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = epochs[0].get_data()\n",
    "data = data.transpose(1, 2, 0).reshape(data.shape[1], -1)\n",
    "\n",
    "cov = np.cov(data)\n",
    "\n",
    "# standardize the data\n",
    "data = StandardScaler().fit_transform(data.T).T\n",
    "\n",
    "# compute the covariance matrix\n",
    "cov_std = np.cov(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the covariance matrix\n",
    "%matplotlib widget\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].imshow(cov)\n",
    "# modify axis to show channel names\n",
    "ax[0].set_xticks(range(0, 53, 2), epochs[0].ch_names[::2], rotation=90)\n",
    "\n",
    "ax[1].imshow(cov_std)\n",
    "# modify axis to show channel names\n",
    "ax[1].set_xticks(range(0, 53, 2), epochs[0].ch_names[::2], rotation=90)\n",
    "e=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "covs = []\n",
    "all_covs = []\n",
    "labels = []\n",
    "all_full_covs = []\n",
    "class_labels = []\n",
    "for sess, ep in enumerate(epochs):\n",
    "    data = ep.get_data()\n",
    "    chn = data.shape[1]\n",
    "    trials = data.shape[0]\n",
    "\n",
    "    data = data.transpose(1, 2, 0).reshape(data.shape[1], -1)\n",
    "\n",
    "    # standardize the data\n",
    "    data = StandardScaler().fit_transform(data.T).T\n",
    "\n",
    "    data = data.reshape(chn, -1, trials)\n",
    "\n",
    "    trial_covs = []\n",
    "    for i in range(trials):\n",
    "        cov = np.cov(data[:, :, i])\n",
    "        trial_covs.append(cov)\n",
    "        all_full_covs.append(cov)\n",
    "\n",
    "        class_labels.append(ep.events[i, 2])\n",
    "    \n",
    "    labels.extend([sess] * trials)\n",
    "\n",
    "    sess_cov = np.mean(np.array(trial_covs), axis=0)\n",
    "\n",
    "    '''\n",
    "    for i in range(trials):\n",
    "        cov = np.cov(data[:, :, i]) - sess_cov\n",
    "\n",
    "        mat = np.triu(cov).reshape(-1)\n",
    "        all_covs.append(mat[mat != 0])\n",
    "    '''\n",
    "\n",
    "    covs.append(sess_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_cov = np.mean(np.array(covs), axis=0)\n",
    "\n",
    "for sess, ep in enumerate(epochs):\n",
    "    data = ep.get_data()\n",
    "    chn = data.shape[1]\n",
    "    trials = data.shape[0]\n",
    "\n",
    "    data = data.transpose(1, 2, 0).reshape(data.shape[1], -1)\n",
    "\n",
    "    # standardize the data\n",
    "    data = StandardScaler().fit_transform(data.T).T\n",
    "\n",
    "    data = data.reshape(chn, -1, trials)\n",
    "\n",
    "    d = avg_cov - covs[sess]\n",
    "\n",
    "    for i in range(trials):\n",
    "        cov = np.cov(data[:, :, i]) + d\n",
    "\n",
    "        mat = np.triu(cov).reshape(-1)\n",
    "        all_covs.append(mat[mat != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save session differences\n",
    "for sess, ep in enumerate(epochs):\n",
    "    d = avg_cov - covs[sess]\n",
    "    outdir = base + f\"/preproc1_40hz_noica/inner_speech_long/avg_cov_diff{sess}.npy\"\n",
    "\n",
    "    np.save(outdir, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_full_covs = np.array(all_full_covs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute mean of covariances across class_labels\n",
    "class_covs = []\n",
    "for cl in np.unique(class_labels):\n",
    "    cov = np.mean(all_full_covs[class_labels == cl], axis=0)\n",
    "    class_covs.append(cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the covariance matrix\n",
    "%matplotlib widget\n",
    "fig, ax = plt.subplots(1, 5, figsize=(10, 5))\n",
    "for i, cov in enumerate(class_covs):\n",
    "    ax[i].imshow(cov)\n",
    "    ax[i].set_xticks(range(0, 53, 2), epochs[0].ch_names[::2], rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "class_std = np.std(np.array(class_covs), axis=0)/np.mean(np.array(class_covs), axis=0)\n",
    "plt.imshow(class_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_std[class_std>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the covariance matrix\n",
    "%matplotlib widget\n",
    "fig, ax = plt.subplots(2, 5, figsize=(10, 5))\n",
    "for i, cov in enumerate(covs):\n",
    "    row = i // 5\n",
    "    col = i % 5\n",
    "    ax[row][col].imshow(cov)\n",
    "    ax[row][col].set_xticks(range(0, 53, 2), epochs[0].ch_names[::2], rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute riemannian distance between each session using covs\n",
    "riemann_dist = []\n",
    "for i in range(len(covs)):\n",
    "    dist = []\n",
    "    for j in range(len(covs)):\n",
    "        dist.append(distance_riemann(covs[i], covs[j]))\n",
    "\n",
    "    riemann_dist.append(np.array(dist))\n",
    "\n",
    "riemann_dist = np.array(riemann_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(riemann_dist, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1286e220c65d4907a3f46cf3b85234af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7fad090d3850>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "plt.imshow(riemann_dist)\n",
    "\n",
    "# add colorbar\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_cov = np.mean(np.array(covs), axis=0)\n",
    "\n",
    "# replace each row and column iteratively of each session with avg_cov and compute riemannian distance\n",
    "riemann_dist = []\n",
    "for i in range(len(covs)):\n",
    "    \n",
    "    dist = []\n",
    "    for j in range(covs[i].shape[0]):\n",
    "        cov = covs[i].copy()\n",
    "        avg_cov_copy = avg_cov.copy()\n",
    "        cov = np.delete(cov, j, axis=0)\n",
    "        cov = np.delete(cov, j, axis=1)\n",
    "\n",
    "        avg_cov_copy = np.delete(avg_cov_copy, j, axis=0)\n",
    "        avg_cov_copy = np.delete(avg_cov_copy, j, axis=1)\n",
    "\n",
    "        d = distance_riemann(cov, avg_cov_copy)\n",
    "        dist.append(d)\n",
    "\n",
    "    riemann_dist.append(np.array(dist))\n",
    "\n",
    "riemann_dist = np.mean(np.array(riemann_dist), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f7ff86816044880aee713ef1f1ae20a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "To show names, a list of names must be provided (see `names` keyword).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/nv/wjmf18wd5_j38vg9v0cthl5h0000gn/T/ipykernel_2470/1686194837.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# plot scores as topomap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'widget'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_topomap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mriemann_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/main/lib/python3.8/site-packages/mne/viz/topomap.py\u001b[0m in \u001b[0;36mplot_topomap\u001b[0;34m(data, pos, vmin, vmax, cmap, sensors, res, axes, names, show_names, mask, mask_params, outlines, contours, image_interp, show, onselect, extrapolate, sphere, border, ch_type, cnorm)\u001b[0m\n\u001b[1;32m    801\u001b[0m             warn(f\"vmax={cnorm.vmax} is implicitly defined by cnorm, ignoring \"\n\u001b[1;32m    802\u001b[0m                  f\"vmax={vmax}.\")\n\u001b[0;32m--> 803\u001b[0;31m     return _plot_topomap(data, pos, vmin, vmax, cmap, sensors, res, axes,\n\u001b[0m\u001b[1;32m    804\u001b[0m                          \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutlines\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m                          \u001b[0mcontours\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_interp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/main/lib/python3.8/site-packages/mne/viz/topomap.py\u001b[0m in \u001b[0;36m_plot_topomap\u001b[0;34m(data, pos, vmin, vmax, cmap, sensors, res, axes, names, show_names, mask, mask_params, outlines, contours, image_interp, show, onselect, extrapolate, sphere, border, ch_type, cnorm)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshow_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 997\u001b[0;31m             raise ValueError(\"To show names, a list of names must be provided\"\n\u001b[0m\u001b[1;32m    998\u001b[0m                              \" (see `names` keyword).\")\n\u001b[1;32m    999\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mshow_names\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: To show names, a list of names must be provided (see `names` keyword)."
     ]
    }
   ],
   "source": [
    "# plot scores as topomap\n",
    "%matplotlib widget\n",
    "mne.viz.plot_topomap(riemann_dist, epochs[0].info, vmin=5, show_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 FPZ 5.628091887427422\n",
      "1 F7 5.537675662951197\n",
      "2 F5 5.6778804233315165\n",
      "4 F1 5.691782249910956\n",
      "5 F2 5.594888473287343\n",
      "6 F4 5.607740234930827\n",
      "7 F6 5.549330285067309\n",
      "8 F8 5.635269990286816\n",
      "9 FT9 5.325363829645282\n",
      "16 FT8 5.696741559773157\n",
      "17 T9 5.610955099107139\n",
      "20 C3 5.6935473515006345\n",
      "26 T10 5.695748890725506\n",
      "34 TP8 5.688637988437199\n",
      "35 TP10 5.689245277047745\n",
      "42 P4 5.590742524875393\n",
      "43 P6 5.623535170405306\n",
      "47 PO4 5.661000651343939\n",
      "49 O1 5.624463319566814\n",
      "50 OZ 5.62356707670934\n",
      "51 O2 5.674926799416303\n"
     ]
    }
   ],
   "source": [
    "for i, ch in enumerate(epochs[0].info['ch_names']):\n",
    "    if riemann_dist[i] < 5.7:\n",
    "        print(i, ch, riemann_dist[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist\n",
    "for i in range(len(covs)):\n",
    "    cov = covs[i].copy()\n",
    "    avg_cov_copy = avg_cov.copy()\n",
    "    cov = np.delete(cov, [1, 5, 6, 7, 9, 17, 42, 50], axis=0)\n",
    "    cov = np.delete(cov, [1, 5, 6, 7, 9, 17, 42, 50], axis=1)\n",
    "\n",
    "    avg_cov_copy = np.delete(avg_cov_copy, [1, 5, 6, 7, 9, 17, 42, 50], axis=0)\n",
    "    avg_cov_copy = np.delete(avg_cov_copy, [1, 5, 6, 7, 9, 17, 42, 50], axis=1)\n",
    "\n",
    "    d = distance_riemann(cov, avg_cov_copy)\n",
    "    dist.append(d)\n",
    "\n",
    "np.mean(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(sess_riemann_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster all_covs with KMeans\n",
    "kmeans = KMeans(n_clusters=6).fit(np.array(all_covs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed = kmeans.transform(np.array(all_covs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the transformed data\n",
    "tsne_data = TSNE(n_components=2).fit_transform(np.array(all_covs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_data = PCA(n_components=10).fit_transform(np.array(all_covs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(labels)\n",
    "class_labels = np.array(class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tsne(tsne_data, labels, ax):\n",
    "    # Get the unique labels\n",
    "    unique_labels = np.unique(labels)\n",
    "\n",
    "    # Plot each cluster with a different color or marker\n",
    "    for label in unique_labels:\n",
    "        mask = labels == label\n",
    "        ax.scatter(tsne_data[mask, 0], tsne_data[mask, 1], label=label, alpha=0.3, s=5)\n",
    "\n",
    "    # Add a legend\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure and axis\n",
    "%matplotlib widget\n",
    "fig, ax = plt.subplots(1, 3, figsize=(10, 5))\n",
    "plot_tsne(tsne_data, labels, ax[0])\n",
    "plot_tsne(tsne_data, kmeans.labels_, ax[1])\n",
    "plot_tsne(tsne_data, class_labels, ax[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure and axis\n",
    "comps = [0, 1]\n",
    "fig, ax = plt.subplots(1, 3, figsize=(10, 5))\n",
    "plot_tsne(pca_data[:, comps], labels, ax[0])\n",
    "plot_tsne(pca_data[:, comps], kmeans.labels_, ax[1])\n",
    "plot_tsne(pca_data[:, comps], class_labels, ax[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def session_lda(chid):\n",
    "    labels = []\n",
    "    data = []\n",
    "    for i, ep in enumerate(epochs):\n",
    "        epoch = ep.get_data()[:, chid, 1000:]\n",
    "        labels.extend([i] * epoch.shape[0])\n",
    "        data.append(epoch[: , ::10]*1e6)\n",
    "\n",
    "    data = np.concatenate(np.array(data), axis=0)\n",
    "\n",
    "    # train LDA model\n",
    "    lda = LDA()\n",
    "    lda.fit(data, labels)\n",
    "\n",
    "    # get accuracy\n",
    "    return lda.score(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "for i in range(len(epochs[0].ch_names)):\n",
    "    scores[epochs[0].ch_names[i]] = session_lda(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot scores as topomap\n",
    "%matplotlib widget\n",
    "mne.viz.plot_topomap(np.array(list(scores.values())), epochs[0].info, vmin=0.1, show_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ch in epochs[0].info['ch_names']:\n",
    "    if scores[ch] > 0.2:\n",
    "        print(ch, scores[ch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raws[0].plot_sensors(ch_type='eeg', kind='topomap', show_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(scores.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick eeg channels\n",
    "raws[0].get_data().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load spatial PFI\n",
    "path = os.path.join('..', 'results', 'disp_epoched', 'eeg', '9sessions_noica', 'standard_cov_longepochs',\n",
    "                    'val_loss_PFIeeg_closest1.npy')\n",
    "pfi_ch1 = np.load(open(path, 'rb'))\n",
    "pfi_ch1 = np.mean(pfi_ch1, axis=0)\n",
    "pfi_ch1 = pfi_ch1[0, 0] - pfi_ch1[:, 1:]\n",
    "\n",
    "evoked_ch1 = mne.EvokedArray(pfi_ch1.T, raws[0].info, tmin=0)\n",
    "\n",
    "%matplotlib widget\n",
    "evoked_ch1.plot_topomap(times=[0], ch_type='eeg', time_unit='ms', scalings=1, units='Gradient magnitude', time_format='', vmin=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find indices of channels in pfi_ch1 that are higher than 0.1\n",
    "chid = []\n",
    "for i, ch in enumerate(raws[0].info['ch_names']):\n",
    "    if pfi_ch1[0, i] > 0.1:\n",
    "        chid.append(i)\n",
    "        print(ch)\n",
    "\n",
    "print(chid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('main')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3818df9f0fda158f80d2404c4b51c3eecd7a0fbc4149212a6ea8c0c98c2a56f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
